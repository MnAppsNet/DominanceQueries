2023.01.01 18:26:28 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/lsp.trace.json or /home/mnapps/.cache/metals/lsp.trace.json[0m
2023.01.01 18:26:28 INFO  logging to file /home/mnapps/DominanceQueries/.metals/metals.log[0m
2023.01.01 18:26:28 INFO  Started: Metals version 0.11.9 in workspace '/home/mnapps/DominanceQueries' for client Visual Studio Code 1.74.2.[0m
2023.01.01 18:26:33 INFO  time: initialize in 5.27s[0m
2023.01.01 18:26:35 WARN  Build server is not auto-connectable.[0m
2023.01.01 18:26:35 WARN  no build target for: /home/mnapps/DominanceQueries/build.sbt[0m
2023.01.01 18:26:37 INFO  running '/usr/lib/jvm/java-11-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -Dsbt.version=1.7.1 -jar /tmp/metals3675522260373122927/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'[0m
2023.01.01 18:26:37 ERROR [info] [launcher] getting org.scala-sbt sbt 1.7.1  (this may take some time)...[0m
2023.01.01 18:26:37 WARN  no build target for: /home/mnapps/DominanceQueries/project/metals.sbt[0m
2023.01.01 18:26:37 WARN  no build target for: /home/mnapps/DominanceQueries/project/project/metals.sbt[0m
2023.01.01 18:26:37 INFO  skipping build import with status 'Started'[0m
2023.01.01 18:27:04 INFO  no build target found for /home/mnapps/DominanceQueries/build.sbt. Using presentation compiler with project's scala-library version: 3.2.0[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/main_2.12/1.7.1/main_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/run_2.12/1.7.1/run_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.16/scala-library-2.12.16.jar ...[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/sbt/1.7.1/sbt-1.7.1.jar ...[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/actions_2.12/1.7.1/actions_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/logic_2.12/1.7.1/logic_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/io_2.12/1.7.0/io_2.12-1.7.0.jar ...[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/main-settings_2.12/1.7.1/main-settings_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:02 ERROR :: loading settings :: url = jar:file:/tmp/metals3675522260373122927/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml[0m
2023.01.01 18:28:02 ERROR :: loading settings :: url = jar:file:/tmp/metals3675522260373122927/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml[0m
2023.01.01 18:28:02 ERROR :: loading settings :: url = jar:file:/tmp/metals3675522260373122927/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml[0m
2023.01.01 18:28:02 ERROR :: loading settings :: url = jar:file:/tmp/metals3675522260373122927/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml[0m
2023.01.01 18:28:02 ERROR :: loading settings :: url = jar:file:/tmp/metals3675522260373122927/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml[0m
2023.01.01 18:28:02 ERROR :: loading settings :: url = jar:file:/tmp/metals3675522260373122927/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml[0m
2023.01.01 18:28:02 ERROR :: loading settings :: url = jar:file:/tmp/metals3675522260373122927/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml[0m
2023.01.01 18:28:02 ERROR :: loading settings :: url = jar:file:/tmp/metals3675522260373122927/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml[0m
2023.01.01 18:28:02 ERROR 	[SUCCESSFUL ] org.scala-sbt#run_2.12;1.7.1!run_2.12.jar (718ms)[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/command_2.12/1.7.1/command_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:02 ERROR 	[SUCCESSFUL ] org.scala-sbt#logic_2.12;1.7.1!logic_2.12.jar (857ms)[0m
2023.01.01 18:28:02 ERROR 	[SUCCESSFUL ] org.scala-sbt#sbt;1.7.1!sbt.jar (858ms)[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/scripted-plugin_2.12/1.7.1/scripted-plugin_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:02 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/collections_2.12/1.7.1/collections_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:03 ERROR 	[SUCCESSFUL ] org.scala-sbt#actions_2.12;1.7.1!actions_2.12.jar (1370ms)[0m
2023.01.01 18:28:03 ERROR 	[SUCCESSFUL ] org.scala-sbt#scripted-plugin_2.12;1.7.1!scripted-plugin_2.12.jar (513ms)[0m
2023.01.01 18:28:03 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/util-logging_2.12/1.7.1/util-logging_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:03 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-lm-integration_2.12/1.7.1/zinc-lm-integration_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:03 ERROR 	[SUCCESSFUL ] org.scala-sbt#main-settings_2.12;1.7.1!main-settings_2.12.jar (2088ms)[0m
2023.01.01 18:28:03 ERROR downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/1.3.0/scala-xml_2.12-1.3.0.jar ...[0m
2023.01.01 18:28:04 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-lm-integration_2.12;1.7.1!zinc-lm-integration_2.12.jar (1120ms)[0m
2023.01.01 18:28:04 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/launcher-interface/1.3.3/launcher-interface-1.3.3.jar ...[0m
2023.01.01 18:28:04 ERROR 	[SUCCESSFUL ] org.scala-sbt#launcher-interface;1.3.3!launcher-interface.jar (805ms)[0m
2023.01.01 18:28:04 ERROR downloading https://repo1.maven.org/maven2/com/github/ben-manes/caffeine/caffeine/2.8.5/caffeine-2.8.5.jar ...[0m
2023.01.01 18:28:04 ERROR 	[SUCCESSFUL ] org.scala-sbt#command_2.12;1.7.1!command_2.12.jar (2712ms)[0m
2023.01.01 18:28:04 ERROR downloading https://repo1.maven.org/maven2/io/get-coursier/lm-coursier-shaded_2.12/2.0.10/lm-coursier-shaded_2.12-2.0.10.jar ...[0m
2023.01.01 18:28:05 ERROR 	[SUCCESSFUL ] org.scala-sbt#io_2.12;1.7.0!io_2.12.jar (3498ms)[0m
2023.01.01 18:28:05 ERROR downloading https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar ...[0m
2023.01.01 18:28:05 ERROR 	[SUCCESSFUL ] org.scala-sbt#collections_2.12;1.7.1!collections_2.12.jar (2744ms)[0m
2023.01.01 18:28:05 ERROR downloading https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar ...[0m
2023.01.01 18:28:05 ERROR 	[SUCCESSFUL ] org.scala-sbt#util-logging_2.12;1.7.1!util-logging_2.12.jar (2737ms)[0m
2023.01.01 18:28:05 ERROR downloading https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-slf4j-impl/2.17.1/log4j-slf4j-impl-2.17.1.jar ...[0m
2023.01.01 18:28:05 ERROR 	[SUCCESSFUL ] org.scala-lang.modules#scala-xml_2.12;1.3.0!scala-xml_2.12.jar(bundle) (2225ms)[0m
2023.01.01 18:28:05 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/librarymanagement-core_2.12/1.7.0/librarymanagement-core_2.12-1.7.0.jar ...[0m
2023.01.01 18:28:07 ERROR 	[SUCCESSFUL ] org.apache.logging.log4j#log4j-slf4j-impl;2.17.1!log4j-slf4j-impl.jar (819ms)[0m
2023.01.01 18:28:07 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/librarymanagement-ivy_2.12/1.7.0/librarymanagement-ivy_2.12-1.7.0.jar ...[0m
2023.01.01 18:28:07 ERROR 	[SUCCESSFUL ] org.apache.logging.log4j#log4j-api;2.17.1!log4j-api.jar (1733ms)[0m
2023.01.01 18:28:07 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/compiler-interface/1.7.1/compiler-interface-1.7.1.jar ...[0m
2023.01.01 18:28:08 ERROR 	[SUCCESSFUL ] org.scala-sbt#compiler-interface;1.7.1!compiler-interface.jar (1259ms)[0m
2023.01.01 18:28:08 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-compile_2.12/1.7.1/zinc-compile_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:08 ERROR 	[SUCCESSFUL ] org.scala-sbt#main_2.12;1.7.1!main_2.12.jar (6871ms)[0m
2023.01.01 18:28:08 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/util-relation_2.12/1.7.1/util-relation_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:08 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-compile_2.12;1.7.1!zinc-compile_2.12.jar (408ms)[0m
2023.01.01 18:28:08 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/util-position_2.12/1.7.1/util-position_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:08 ERROR 	[SUCCESSFUL ] org.scala-sbt#librarymanagement-core_2.12;1.7.0!librarymanagement-core_2.12.jar (2658ms)[0m
2023.01.01 18:28:08 ERROR downloading https://repo1.maven.org/maven2/com/eed3si9n/sjson-new-scalajson_2.12/0.9.1/sjson-new-scalajson_2.12-0.9.1.jar ...[0m
2023.01.01 18:28:08 ERROR 	[SUCCESSFUL ] org.scala-sbt#util-relation_2.12;1.7.1!util-relation_2.12.jar (467ms)[0m
2023.01.01 18:28:08 ERROR downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.16/scala-reflect-2.12.16.jar ...[0m
2023.01.01 18:28:08 ERROR 	[SUCCESSFUL ] com.eed3si9n#sjson-new-scalajson_2.12;0.9.1!sjson-new-scalajson_2.12.jar (413ms)[0m
2023.01.01 18:28:08 ERROR downloading https://repo1.maven.org/maven2/com/eed3si9n/sjson-new-core_2.12/0.9.1/sjson-new-core_2.12-0.9.1.jar ...[0m
2023.01.01 18:28:08 ERROR 	[SUCCESSFUL ] org.scala-sbt#util-position_2.12;1.7.1!util-position_2.12.jar (589ms)[0m
2023.01.01 18:28:08 ERROR downloading https://repo1.maven.org/maven2/com/eed3si9n/shaded-jawn-parser_2.12/0.9.1/shaded-jawn-parser_2.12-0.9.1.jar ...[0m
2023.01.01 18:28:09 ERROR 	[SUCCESSFUL ] org.scala-sbt#librarymanagement-ivy_2.12;1.7.0!librarymanagement-ivy_2.12.jar (2764ms)[0m
2023.01.01 18:28:09 ERROR downloading https://repo1.maven.org/maven2/com/eed3si9n/shaded-scalajson_2.12/1.0.0-M4/shaded-scalajson_2.12-1.0.0-M4.jar ...[0m
2023.01.01 18:28:09 ERROR 	[SUCCESSFUL ] com.eed3si9n#shaded-jawn-parser_2.12;0.9.1!shaded-jawn-parser_2.12.jar (613ms)[0m
2023.01.01 18:28:09 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/completion_2.12/1.7.1/completion_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:09 ERROR 	[SUCCESSFUL ] com.eed3si9n#shaded-scalajson_2.12;1.0.0-M4!shaded-scalajson_2.12.jar (614ms)[0m
2023.01.01 18:28:09 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/task-system_2.12/1.7.1/task-system_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:11 ERROR 	[SUCCESSFUL ] org.scala-sbt#task-system_2.12;1.7.1!task-system_2.12.jar (921ms)[0m
2023.01.01 18:28:11 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/tasks_2.12/1.7.1/tasks_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:11 ERROR 	[SUCCESSFUL ] org.scala-sbt#completion_2.12;1.7.1!completion_2.12.jar (1741ms)[0m
2023.01.01 18:28:11 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/testing_2.12/1.7.1/testing_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:11 ERROR 	[SUCCESSFUL ] org.scala-sbt#tasks_2.12;1.7.1!tasks_2.12.jar (819ms)[0m
2023.01.01 18:28:11 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/util-tracking_2.12/1.7.1/util-tracking_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:12 ERROR 	[SUCCESSFUL ] com.github.ben-manes.caffeine#caffeine;2.8.5!caffeine.jar (7064ms)[0m
2023.01.01 18:28:12 ERROR downloading https://repo1.maven.org/maven2/org/jline/jline-terminal/3.19.0/jline-terminal-3.19.0.jar ...[0m
2023.01.01 18:28:12 ERROR 	[SUCCESSFUL ] org.scala-sbt#util-tracking_2.12;1.7.1!util-tracking_2.12.jar (614ms)[0m
2023.01.01 18:28:12 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-classpath_2.12/1.7.1/zinc-classpath_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:12 ERROR 	[SUCCESSFUL ] com.eed3si9n#sjson-new-core_2.12;0.9.1!sjson-new-core_2.12.jar (3713ms)[0m
2023.01.01 18:28:12 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-apiinfo_2.12/1.7.1/zinc-apiinfo_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:14 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-classpath_2.12;1.7.1!zinc-classpath_2.12.jar (1499ms)[0m
2023.01.01 18:28:14 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc_2.12/1.7.1/zinc_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:14 ERROR 	[SUCCESSFUL ] org.scala-sbt#testing_2.12;1.7.1!testing_2.12.jar (2463ms)[0m
2023.01.01 18:28:14 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-apiinfo_2.12;1.7.1!zinc-apiinfo_2.12.jar (1207ms)[0m
2023.01.01 18:28:14 ERROR 	[SUCCESSFUL ] org.jline#jline-terminal;3.19.0!jline-terminal.jar (1945ms)[0m
2023.01.01 18:28:14 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/jline/jline/2.14.7-sbt-a1b0ffbb8f64bb820f4f84a0c07a0c0964507493/jline-2.14.7-sbt-a1b0ffbb8f64bb820f4f84a0c07a0c0964507493.jar ...[0m
2023.01.01 18:28:14 ERROR downloading https://repo1.maven.org/maven2/org/jline/jline-reader/3.19.0/jline-reader-3.19.0.jar ...[0m
2023.01.01 18:28:14 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/util-control_2.12/1.7.1/util-control_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:14 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc_2.12;1.7.1!zinc_2.12.jar (953ms)[0m
2023.01.01 18:28:14 ERROR downloading https://repo1.maven.org/maven2/org/jline/jline-builtins/3.19.0/jline-builtins-3.19.0.jar ...[0m
2023.01.01 18:28:15 ERROR 	[SUCCESSFUL ] org.scala-sbt#util-control_2.12;1.7.1!util-control_2.12.jar (875ms)[0m
2023.01.01 18:28:15 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/util-interface/1.7.1/util-interface-1.7.1.jar ...[0m
2023.01.01 18:28:15 ERROR 	[SUCCESSFUL ] org.apache.logging.log4j#log4j-core;2.17.1!log4j-core.jar (9581ms)[0m
2023.01.01 18:28:15 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/core-macros_2.12/1.7.1/core-macros_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:15 ERROR 	[SUCCESSFUL ] org.scala-sbt.jline#jline;2.14.7-sbt-a1b0ffbb8f64bb820f4f84a0c07a0c0964507493!jline.jar (1126ms)[0m
2023.01.01 18:28:15 ERROR downloading https://repo1.maven.org/maven2/org/jline/jline-terminal-jna/3.19.0/jline-terminal-jna-3.19.0.jar ...[0m
2023.01.01 18:28:16 ERROR 	[SUCCESSFUL ] org.scala-sbt#util-interface;1.7.1!util-interface.jar (1069ms)[0m
2023.01.01 18:28:16 ERROR 	[SUCCESSFUL ] org.jline#jline-terminal-jna;3.19.0!jline-terminal-jna.jar (819ms)[0m
2023.01.01 18:28:16 ERROR downloading https://repo1.maven.org/maven2/org/jline/jline-terminal-jansi/3.19.0/jline-terminal-jansi-3.19.0.jar ...[0m
2023.01.01 18:28:16 ERROR downloading https://repo1.maven.org/maven2/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar ...[0m
2023.01.01 18:28:16 ERROR 	[SUCCESSFUL ] org.scala-sbt#core-macros_2.12;1.7.1!core-macros_2.12.jar (1374ms)[0m
2023.01.01 18:28:16 ERROR downloading https://repo1.maven.org/maven2/org/scala-lang/scala-compiler/2.12.16/scala-compiler-2.12.16.jar ...[0m
2023.01.01 18:28:16 ERROR 	[SUCCESSFUL ] org.jline#jline-reader;3.19.0!jline-reader.jar (2354ms)[0m
2023.01.01 18:28:16 ERROR downloading https://repo1.maven.org/maven2/org/fusesource/jansi/jansi/2.1.0/jansi-2.1.0.jar ...[0m
2023.01.01 18:28:16 ERROR 	[SUCCESSFUL ] org.jline#jline-builtins;3.19.0!jline-builtins.jar (1749ms)[0m
2023.01.01 18:28:16 ERROR downloading https://repo1.maven.org/maven2/com/swoval/file-tree-views/2.1.9/file-tree-views-2.1.9.jar ...[0m
2023.01.01 18:28:16 ERROR 	[SUCCESSFUL ] org.jline#jline-terminal-jansi;3.19.0!jline-terminal-jansi.jar (620ms)[0m
2023.01.01 18:28:16 ERROR downloading https://repo1.maven.org/maven2/net/java/dev/jna/jna/5.12.0/jna-5.12.0.jar ...[0m
2023.01.01 18:28:16 ERROR 	[SUCCESSFUL ] com.lmax#disruptor;3.4.2!disruptor.jar (819ms)[0m
2023.01.01 18:28:16 ERROR downloading https://repo1.maven.org/maven2/net/java/dev/jna/jna-platform/5.12.0/jna-platform-5.12.0.jar ...[0m
2023.01.01 18:28:18 ERROR 	[SUCCESSFUL ] com.swoval#file-tree-views;2.1.9!file-tree-views.jar (1739ms)[0m
2023.01.01 18:28:18 ERROR downloading https://repo1.maven.org/maven2/org/jline/jline-style/3.19.0/jline-style-3.19.0.jar ...[0m
2023.01.01 18:28:18 ERROR 	[SUCCESSFUL ] org.scala-lang#scala-library;2.12.16!scala-library.jar (16813ms)[0m
2023.01.01 18:28:18 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/util-cache_2.12/1.7.1/util-cache_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:18 ERROR 	[SUCCESSFUL ] org.jline#jline-style;3.19.0!jline-style.jar (513ms)[0m
2023.01.01 18:28:18 ERROR downloading https://repo1.maven.org/maven2/com/eed3si9n/sjson-new-murmurhash_2.12/0.9.1/sjson-new-murmurhash_2.12-0.9.1.jar ...[0m
2023.01.01 18:28:18 ERROR 	[SUCCESSFUL ] com.eed3si9n#sjson-new-murmurhash_2.12;0.9.1!sjson-new-murmurhash_2.12.jar (410ms)[0m
2023.01.01 18:28:18 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/test-agent/1.7.1/test-agent-1.7.1.jar ...[0m
2023.01.01 18:28:19 ERROR 	[SUCCESSFUL ] org.fusesource.jansi#jansi;2.1.0!jansi.jar (3071ms)[0m
2023.01.01 18:28:19 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/test-interface/1.0/test-interface-1.0.jar ...[0m
2023.01.01 18:28:19 ERROR 	[SUCCESSFUL ] org.scala-sbt#test-agent;1.7.1!test-agent.jar (468ms)[0m
2023.01.01 18:28:19 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/compiler-bridge_2.12/1.7.1/compiler-bridge_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:19 ERROR 	[SUCCESSFUL ] org.scala-sbt#test-interface;1.0!test-interface.jar (422ms)[0m
2023.01.01 18:28:19 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-classfile_2.12/1.7.1/zinc-classfile_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:19 ERROR 	[SUCCESSFUL ] org.scala-sbt#util-cache_2.12;1.7.1!util-cache_2.12.jar (1444ms)[0m
2023.01.01 18:28:19 ERROR downloading https://repo1.maven.org/maven2/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar ...[0m
2023.01.01 18:28:21 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-classfile_2.12;1.7.1!zinc-classfile_2.12.jar (1624ms)[0m
2023.01.01 18:28:21 ERROR 	[SUCCESSFUL ] org.scala-sbt#compiler-bridge_2.12;1.7.1!compiler-bridge_2.12.jar (1782ms)[0m
2023.01.01 18:28:21 ERROR downloading https://repo1.maven.org/maven2/com/eed3si9n/gigahorse-apache-http_2.12/0.7.0/gigahorse-apache-http_2.12-0.7.0.jar ...[0m
2023.01.01 18:28:21 ERROR downloading https://repo1.maven.org/maven2/com/eed3si9n/gigahorse-core_2.12/0.7.0/gigahorse-core_2.12-0.7.0.jar ...[0m
2023.01.01 18:28:21 ERROR 	[SUCCESSFUL ] com.jcraft#jsch;0.1.54!jsch.jar (1726ms)[0m
2023.01.01 18:28:21 ERROR downloading https://repo1.maven.org/maven2/com/eed3si9n/shaded-apache-httpasyncclient/0.7.0/shaded-apache-httpasyncclient-0.7.0.jar ...[0m
2023.01.01 18:28:21 ERROR 	[SUCCESSFUL ] com.eed3si9n#gigahorse-apache-http_2.12;0.7.0!gigahorse-apache-http_2.12.jar (736ms)[0m
2023.01.01 18:28:21 ERROR downloading https://repo1.maven.org/maven2/com/typesafe/ssl-config-core_2.12/0.6.1/ssl-config-core_2.12-0.6.1.jar ...[0m
2023.01.01 18:28:23 ERROR 	[SUCCESSFUL ] net.java.dev.jna#jna;5.12.0!jna.jar (6255ms)[0m
2023.01.01 18:28:23 ERROR downloading https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar ...[0m
2023.01.01 18:28:23 ERROR 	[SUCCESSFUL ] com.eed3si9n#gigahorse-core_2.12;0.7.0!gigahorse-core_2.12.jar (1394ms)[0m
2023.01.01 18:28:23 ERROR downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.28/slf4j-api-1.7.28.jar ...[0m
2023.01.01 18:28:23 ERROR 	[SUCCESSFUL ] org.reactivestreams#reactive-streams;1.0.3!reactive-streams.jar (389ms)[0m
2023.01.01 18:28:23 ERROR downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.2/config-1.4.2.jar ...[0m
2023.01.01 18:28:23 ERROR 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.28!slf4j-api.jar (644ms)[0m
2023.01.01 18:28:23 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-core_2.12/1.7.1/zinc-core_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:24 ERROR 	[SUCCESSFUL ] com.typesafe#ssl-config-core_2.12;0.6.1!ssl-config-core_2.12.jar(bundle) (1816ms)[0m
2023.01.01 18:28:24 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-persist_2.12/1.7.1/zinc-persist_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:24 ERROR 	[SUCCESSFUL ] net.java.dev.jna#jna-platform;5.12.0!jna-platform.jar (7366ms)[0m
2023.01.01 18:28:24 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-compile-core_2.12/1.7.1/zinc-compile-core_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:25 ERROR 	[SUCCESSFUL ] com.typesafe#config;1.4.2!config.jar(bundle) (1841ms)[0m
2023.01.01 18:28:25 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/zinc-persist-core-assembly/1.7.1/zinc-persist-core-assembly-1.7.1.jar ...[0m
2023.01.01 18:28:25 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-compile-core_2.12;1.7.1!zinc-compile-core_2.12.jar (1258ms)[0m
2023.01.01 18:28:25 ERROR downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.12/1.1.2/scala-parser-combinators_2.12-1.1.2.jar ...[0m
2023.01.01 18:28:25 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-persist_2.12;1.7.1!zinc-persist_2.12.jar (1568ms)[0m
2023.01.01 18:28:25 ERROR downloading https://repo1.maven.org/maven2/net/openhft/zero-allocation-hashing/0.10.1/zero-allocation-hashing-0.10.1.jar ...[0m
2023.01.01 18:28:26 ERROR 	[SUCCESSFUL ] net.openhft#zero-allocation-hashing;0.10.1!zero-allocation-hashing.jar(bundle) (703ms)[0m
2023.01.01 18:28:26 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/sbinary_2.12/0.5.1/sbinary_2.12-0.5.1.jar ...[0m
2023.01.01 18:28:26 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-core_2.12;1.7.1!zinc-core_2.12.jar (3277ms)[0m
2023.01.01 18:28:26 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/protocol_2.12/1.7.1/protocol_2.12-1.7.1.jar ...[0m
2023.01.01 18:28:26 ERROR 	[SUCCESSFUL ] org.scala-lang.modules#scala-parser-combinators_2.12;1.1.2!scala-parser-combinators_2.12.jar(bundle) (1505ms)[0m
2023.01.01 18:28:26 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/template-resolver/0.1/template-resolver-0.1.jar ...[0m
2023.01.01 18:28:27 ERROR 	[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.16!scala-reflect.jar (18275ms)[0m
2023.01.01 18:28:27 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/ipcsocket/ipcsocket/1.5.0/ipcsocket-1.5.0.jar ...[0m
2023.01.01 18:28:27 ERROR 	[SUCCESSFUL ] org.scala-sbt#sbinary_2.12;0.5.1!sbinary_2.12.jar (1019ms)[0m
2023.01.01 18:28:27 ERROR downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.4.1/checker-qual-3.4.1.jar ...[0m
2023.01.01 18:28:27 ERROR 	[SUCCESSFUL ] org.scala-sbt#template-resolver;0.1!template-resolver.jar (467ms)[0m
2023.01.01 18:28:27 ERROR downloading https://repo1.maven.org/maven2/com/google/errorprone/error_prone_annotations/2.4.0/error_prone_annotations-2.4.0.jar ...[0m
2023.01.01 18:28:27 ERROR 	[SUCCESSFUL ] com.google.errorprone#error_prone_annotations;2.4.0!error_prone_annotations.jar (659ms)[0m
2023.01.01 18:28:27 ERROR downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.6.0/scala-collection-compat_2.12-2.6.0.jar ...[0m
2023.01.01 18:28:29 ERROR 	[SUCCESSFUL ] org.scala-sbt.ipcsocket#ipcsocket;1.5.0!ipcsocket.jar (1265ms)[0m
2023.01.01 18:28:29 ERROR downloading https://repo1.maven.org/maven2/org/scala-sbt/ivy/ivy/2.3.0-sbt-fbc4f586aeeb1591710b14eb4f41b94880dcd745/ivy-2.3.0-sbt-fbc4f586aeeb1591710b14eb4f41b94880dcd745.jar ...[0m
2023.01.01 18:28:29 ERROR 	[SUCCESSFUL ] org.checkerframework#checker-qual;3.4.1!checker-qual.jar (1347ms)[0m
2023.01.01 18:28:30 ERROR 	[SUCCESSFUL ] org.scala-lang.modules#scala-collection-compat_2.12;2.6.0!scala-collection-compat_2.12.jar (1846ms)[0m
2023.01.01 18:28:32 ERROR 	[SUCCESSFUL ] com.eed3si9n#shaded-apache-httpasyncclient;0.7.0!shaded-apache-httpasyncclient.jar (9972ms)[0m
2023.01.01 18:28:32 ERROR 	[SUCCESSFUL ] org.scala-sbt#protocol_2.12;1.7.1!protocol_2.12.jar (4949ms)[0m
2023.01.01 18:28:32 ERROR 	[SUCCESSFUL ] org.scala-sbt#zinc-persist-core-assembly;1.7.1!zinc-persist-core-assembly.jar (7107ms)[0m
2023.01.01 18:28:33 ERROR 	[SUCCESSFUL ] org.scala-sbt.ivy#ivy;2.3.0-sbt-fbc4f586aeeb1591710b14eb4f41b94880dcd745!ivy.jar (4310ms)[0m
2023.01.01 18:28:35 ERROR 	[SUCCESSFUL ] io.get-coursier#lm-coursier-shaded_2.12;2.0.10!lm-coursier-shaded_2.12.jar (29415ms)[0m
2023.01.01 18:28:38 ERROR 	[SUCCESSFUL ] org.scala-lang#scala-compiler;2.12.16!scala-compiler.jar (21809ms)[0m
2023.01.01 18:28:38 ERROR :: retrieving :: org.scala-sbt#boot-app[0m
2023.01.01 18:28:38 ERROR 	confs: [default][0m
2023.01.01 18:28:38 ERROR 	81 artifacts copied, 0 already retrieved[0m
2023.01.01 18:28:38 ERROR [info] [launcher] getting Scala 2.12.16 (for sbt)...[0m
2023.01.01 18:28:38 ERROR downloading https://repo1.maven.org/maven2/jline/jline/2.14.6/jline-2.14.6.jar ...[0m
2023.01.01 18:28:38 ERROR downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar ...[0m
2023.01.01 18:28:40 ERROR 	[SUCCESSFUL ] jline#jline;2.14.6!jline.jar (541ms)[0m
2023.01.01 18:28:41 ERROR 	[SUCCESSFUL ] org.scala-lang.modules#scala-xml_2.12;1.0.6!scala-xml_2.12.jar(bundle) (1667ms)[0m
2023.01.01 18:28:41 ERROR :: retrieving :: org.scala-sbt#boot-scala[0m
2023.01.01 18:28:41 ERROR 	confs: [default][0m
2023.01.01 18:28:41 ERROR 	5 artifacts copied, 0 already retrieved[0m
2023.01.01 18:28:42 INFO  [info] Updated file /home/mnapps/DominanceQueries/project/build.properties: set sbt.version to 1.7.1[0m
2023.01.01 18:28:42 INFO  [info] welcome to sbt 1.7.1 (Ubuntu Java 11.0.17)[0m
2023.01.01 18:28:44 INFO  [info] loading settings for project dominancequeries-build-build from metals.sbt ...[0m
2023.01.01 18:28:44 INFO  [info] loading project definition from /home/mnapps/DominanceQueries/project/project[0m
2023.01.01 18:29:04 INFO  [info] loading settings for project dominancequeries-build from metals.sbt ...[0m
2023.01.01 18:29:04 INFO  [info] loading project definition from /home/mnapps/DominanceQueries/project[0m
2023.01.01 18:29:49 INFO  [success] Generated .bloop/dominancequeries-build.json[0m
2023.01.01 18:29:49 INFO  [success] Total time: 46 s, completed Jan 1, 2023, 6:29:50 PM[0m
2023.01.01 18:29:51 INFO  [info] loading settings for project sample from build.sbt ...[0m
2023.01.01 18:29:51 INFO  [info] set current project to DominanceQueries (in build file:/home/mnapps/DominanceQueries/)[0m
2023.01.01 18:33:00 INFO  [success] Generated .bloop/sample-test.json[0m
2023.01.01 18:33:00 INFO  [success] Generated .bloop/sample.json[0m
2023.01.01 18:33:00 INFO  [success] Total time: 189 s (03:09), completed Jan 1, 2023, 6:33:00 PM[0m
2023.01.01 18:33:00 INFO  time: ran 'sbt bloopInstall' in 6m23s[0m
2023.01.01 18:33:00 INFO  Attempting to connect to the build server...[0m
2023.01.01 18:33:00 INFO  Setting up current java home /usr/lib/jvm/java-11-openjdk-amd64 in /home/mnapps/.bloop/bloop.json[0m
2023.01.01 18:34:02 ERROR Starting the bsp launcher for bloop...[0m
2023.01.01 18:34:02 ERROR Opening a bsp server connection with 'bsp --protocol local --socket /tmp/bsp-launcher4411853348566357158/bsp.socket'...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR error: Giving up on waiting for a connection, printing embedded bloop logs:[0m
2023.01.01 18:34:02 ERROR > No server running at 127.0.0.1:8212, let's fire one...[0m
2023.01.01 18:34:02 ERROR > Resolving ch.epfl.scala:bloop-frontend_2.12:1.5.4...[0m
2023.01.01 18:34:02 ERROR error: Trying a tcp-based connection to the server instead...[0m
2023.01.01 18:34:02 ERROR Opening a bsp server connection with 'bsp --protocol tcp --port 18594'...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR Waiting for the bsp connection to come up...[0m
2023.01.01 18:34:02 ERROR error: Giving up on waiting for a connection, printing embedded bloop logs:[0m
2023.01.01 18:34:02 ERROR > No server running at 127.0.0.1:8212, let's fire one...[0m
2023.01.01 18:34:02 ERROR > Resolving ch.epfl.scala:bloop-frontend_2.12:1.5.4...[0m
2023.01.01 18:34:02 ERROR error: The launcher failed to establish a bsp connection, aborting...[0m
2023.01.01 18:34:02 ERROR Failed to connect with build server, no functionality will work.java.lang.RuntimeException: The server did not start, got FailedToOpenBspConnection
	at bloop.launcher.LauncherMain.failPromise$1(Launcher.scala:92)
	at bloop.launcher.LauncherMain.runLauncher(Launcher.scala:119)
	at scala.meta.internal.metals.BloopServers$$anon$2.run(BloopServers.scala:496)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.01.01 18:50:05 INFO  shutting down Metals[0m
2023.01.01 18:50:14 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/lsp.trace.json or /home/mnapps/.cache/metals/lsp.trace.json[0m
2023.01.01 18:50:15 INFO  logging to file /home/mnapps/DominanceQueries/.metals/metals.log[0m
2023.01.01 18:50:15 INFO  Started: Metals version 0.11.9 in workspace '/home/mnapps/DominanceQueries' for client Visual Studio Code 1.74.2.[0m
2023.01.01 18:50:16 INFO  time: initialize in 1.08s[0m
2023.01.01 18:50:17 INFO  Attempting to connect to the build server...[0m
2023.01.01 18:50:17 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.01 18:50:17 INFO  skipping build import with status 'Installed'[0m
2023.01.01 18:50:21 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.01 18:50:21 INFO  no build target found for /home/mnapps/DominanceQueries/build.sbt. Using presentation compiler with project's scala-library version: 3.2.0[0m
2023.01.01 18:50:23 INFO  time: code lens generation in 5.01s[0m
2023.01.01 18:50:31 INFO  Attempting to connect to the build server...[0m
2023.01.01 18:50:31 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.01 18:50:31 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/project/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.01 18:50:41 INFO  time: Connected to build server in 24s[0m
2023.01.01 18:50:41 INFO  Connected to Build server: Bloop v1.5.4[0m
2023.01.01 18:50:41 INFO  time: Imported build in 0.12s[0m
2023.01.01 18:50:54 WARN  Could not find java sources in /usr/lib/jvm/src.zip, /usr/lib/jvm/lib/src.zip, /usr/lib/jvm/java-11-openjdk-amd64/src.zip, /usr/lib/jvm/java-11-openjdk-amd64/lib/src.zip. Java symbols will not be available.[0m
2023.01.01 18:50:57 WARN  Could not find java sources in /usr/lib/jvm/src.zip, /usr/lib/jvm/lib/src.zip, /usr/lib/jvm/java-11-openjdk-amd64/src.zip, /usr/lib/jvm/java-11-openjdk-amd64/lib/src.zip. Java symbols will not be available.[0m
2023.01.01 18:50:57 WARN  Could not find java sources in /usr/lib/jvm/src.zip, /usr/lib/jvm/lib/src.zip, /usr/lib/jvm/java-11-openjdk-amd64/src.zip, /usr/lib/jvm/java-11-openjdk-amd64/lib/src.zip. Java symbols will not be available.[0m
2023.01.01 18:50:57 INFO  time: indexed workspace in 15s[0m
2023.01.01 18:51:04 INFO  time: code lens generation in 1.08s[0m
2023.01.01 18:56:42 INFO  shutting down Metals[0m
2023.01.01 18:56:42 INFO  Shut down connection with build server.[0m
2023.01.01 18:56:42 INFO  Shut down connection with build server.[0m
2023.01.01 18:56:50 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/lsp.trace.json or /home/mnapps/.cache/metals/lsp.trace.json[0m
2023.01.01 18:56:51 INFO  logging to file /home/mnapps/DominanceQueries/.metals/metals.log[0m
2023.01.01 18:56:51 INFO  Started: Metals version 0.11.9 in workspace '/home/mnapps/DominanceQueries' for client Visual Studio Code 1.74.2.[0m
2023.01.01 18:56:52 INFO  time: initialize in 1.09s[0m
2023.01.01 18:56:53 INFO  Attempting to connect to the build server...[0m
2023.01.01 18:56:53 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.01 18:56:54 INFO  skipping build import with status 'Installed'[0m
2023.01.01 18:56:54 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.01 18:56:54 INFO  Attempting to connect to the build server...[0m
2023.01.01 18:56:54 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.01 18:56:54 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/project/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.01 18:56:54 INFO  time: Connected to build server in 0.54s[0m
2023.01.01 18:56:54 INFO  Connected to Build server: Bloop v1.5.4[0m
2023.01.01 18:56:56 INFO  no build target found for /home/mnapps/DominanceQueries/build.sbt. Using presentation compiler with project's scala-library version: 3.2.0[0m
2023.01.01 18:56:56 INFO  time: code lens generation in 2.44s[0m
2023.01.01 18:56:59 INFO  time: indexed workspace in 2.33s[0m
2023.01.01 18:57:23 INFO  running '/usr/lib/jvm/java-11-openjdk-amd64/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals18280736449668489198/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'[0m
2023.01.01 18:57:24 INFO  [info] welcome to sbt 1.7.1 (Ubuntu Java 11.0.17)[0m
2023.01.01 18:57:24 INFO  [info] loading settings for project dominancequeries-build-build from metals.sbt ...[0m
2023.01.01 18:57:26 INFO  [info] loading project definition from /home/mnapps/DominanceQueries/project/project[0m
2023.01.01 18:57:26 INFO  [info] loading settings for project dominancequeries-build from metals.sbt ...[0m
2023.01.01 18:57:26 INFO  [info] loading project definition from /home/mnapps/DominanceQueries/project[0m
2023.01.01 18:57:28 INFO  [success] Generated .bloop/dominancequeries-build.json[0m
2023.01.01 18:57:28 INFO  [success] Total time: 2 s, completed Jan 1, 2023, 6:57:28 PM[0m
2023.01.01 18:57:30 INFO  [info] loading settings for project sample from build.sbt ...[0m
2023.01.01 18:57:30 INFO  [info] set current project to DominanceQueries (in build file:/home/mnapps/DominanceQueries/)[0m
2023.01.01 18:57:37 INFO  [success] Generated .bloop/sample-test.json[0m
2023.01.01 18:57:37 INFO  [success] Generated .bloop/sample.json[0m
2023.01.01 18:57:37 INFO  [success] Total time: 7 s, completed Jan 1, 2023, 6:57:37 PM[0m
2023.01.01 18:57:38 INFO  time: ran 'sbt bloopInstall' in 14s[0m
2023.01.01 18:57:38 INFO  Disconnecting from Bloop session...[0m
2023.01.01 18:57:38 INFO  Shut down connection with build server.[0m
2023.01.01 18:57:38 INFO  Shut down connection with build server.[0m
2023.01.01 18:57:38 INFO  Attempting to connect to the build server...[0m
2023.01.01 18:57:38 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.01 18:57:50 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.01 18:57:50 INFO  Attempting to connect to the build server...[0m
2023.01.01 18:57:50 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.01 18:57:50 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/project/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.01 18:57:50 INFO  time: Connected to build server in 11s[0m
2023.01.01 18:57:50 INFO  Connected to Build server: Bloop v1.5.4[0m
2023.01.01 18:57:52 INFO  time: indexed workspace in 2s[0m
2023.01.01 18:57:54 INFO  time: code lens generation in 1.2s[0m
2023.01.01 18:59:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 18:59:15 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1m 24.926s)[0m
2023.01.01 18:59:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 18:59:22 INFO  time: compiled sample in 7.45s[0m
Jan 01, 2023 6:59:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 69
Jan 01, 2023 6:59:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 70
Jan 01, 2023 6:59:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 71
Jan 01, 2023 6:59:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 74
Jan 01, 2023 6:59:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 75
2023.01.01 18:59:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 18:59:41 INFO  time: compiled sample in 0.92s[0m
2023.01.01 19:00:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:00:03 INFO  time: compiled sample in 0.73s[0m
2023.01.01 19:00:09 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:00:09 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:00:09 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:00:12 INFO  Trying to attach to remote debuggee VM localhost:32831 .[0m
2023.01.01 19:00:12 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:00:12 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:00:12 INFO  Closing debug server tcp://0.0.0.0:44347[0m
2023.01.01 19:00:16 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 2m 26.294s)[0m
2023.01.01 19:00:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:00:16 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:00:16 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:00:18 INFO  Trying to attach to remote debuggee VM localhost:52077 .[0m
2023.01.01 19:00:18 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:00:22 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:00:22 INFO  Closing debug server tcp://0.0.0.0:42161[0m
Jan 01, 2023 7:00:22 PM org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Socket closed
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Socket closed
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:146)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:65)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.net.SocketException: Socket closed
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:113)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 16 more

Jan 01, 2023 7:27:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 277
2023.01.01 19:27:21 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:27:21 INFO  time: compiled sample in 0.3s[0m
2023.01.01 19:27:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:27:29 INFO  time: compiled sample in 0.11s[0m
2023.01.01 19:28:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:28:31 INFO  time: compiled sample in 0.11s[0m
2023.01.01 19:28:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:28:39 INFO  time: compiled sample in 0.14s[0m
2023.01.01 19:28:48 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:28:48 INFO  time: compiled sample in 0.55s[0m
2023.01.01 19:28:51 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:28:51 INFO  time: compiled sample in 0.49s[0m
2023.01.01 19:29:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:29:19 INFO  time: compiled sample in 0.54s[0m
2023.01.01 19:35:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:35:44 INFO  time: compiled sample in 0.42s[0m
2023.01.01 19:35:50 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 37m 59.83s)[0m
2023.01.01 19:35:50 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:35:50 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:35:50 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:35:51 INFO  Trying to attach to remote debuggee VM localhost:34315 .[0m
2023.01.01 19:35:51 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:35:51 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:35:54 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:35:54 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:35:54 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:35:54 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:35:54 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:35:56 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:35:56 INFO  Closing debug server tcp://0.0.0.0:41749[0m
2023.01.01 19:36:02 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 38m 12.358s)[0m
2023.01.01 19:36:02 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:36:02 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:36:02 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:36:03 INFO  Trying to attach to remote debuggee VM localhost:40725 .[0m
2023.01.01 19:36:03 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:36:03 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:36:07 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:36:07 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:36:07 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:36:07 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:36:07 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:36:37 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:36:37 INFO  Closing debug server tcp://0.0.0.0:41591[0m
2023.01.01 19:38:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:38:29 INFO  time: compiled sample in 0.1s[0m
2023.01.01 19:38:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:38:40 INFO  time: compiled sample in 0.1s[0m
2023.01.01 19:39:18 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:39:18 INFO  time: compiled sample in 0.1s[0m
2023.01.01 19:39:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:39:29 INFO  time: compiled sample in 0.1s[0m
Jan 01, 2023 7:40:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 988
2023.01.01 19:40:42 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:40:42 INFO  time: compiled sample in 87ms[0m
2023.01.01 19:40:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:40:53 INFO  time: compiled sample in 87ms[0m
2023.01.01 19:41:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:41:07 INFO  time: compiled sample in 0.24s[0m
Jan 01, 2023 7:41:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.debug.DebugProvider$WorkspaceErrorsException$: Cannot run class, since the workspace has errors.
java.util.concurrent.CompletionException: scala.meta.internal.metals.debug.DebugProvider$WorkspaceErrorsException$: Cannot run class, since the workspace has errors.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.uniAcceptNow(CompletableFuture.java:743)
	at java.base/java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:731)
	at java.base/java.util.concurrent.CompletableFuture.thenAcceptAsync(CompletableFuture.java:2112)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.thenAccept(FutureConvertersImpl.scala:37)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleRequest(RemoteEndpoint.java:279)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:190)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: scala.meta.internal.metals.debug.DebugProvider$WorkspaceErrorsException$: Cannot run class, since the workspace has errors.
	at scala.meta.internal.metals.debug.DebugProvider$WorkspaceErrorsException$.<clinit>(DebugProvider.scala:873)
	at scala.meta.internal.metals.debug.DebugProvider.ensureNoWorkspaceErrors(DebugProvider.scala:383)
	at scala.meta.internal.metals.MetalsLanguageServer.executeCommand(MetalsLanguageServer.scala:1943)
	at jdk.internal.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:65)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.request(GenericEndpoint.java:120)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleRequest(RemoteEndpoint.java:261)
	... 9 more

2023.01.01 19:41:10 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:41:10 INFO  time: compiled sample in 99ms[0m
2023.01.01 19:41:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:41:19 INFO  time: compiled sample in 78ms[0m
2023.01.01 19:41:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:41:24 INFO  time: compiled sample in 0.18s[0m
2023.01.01 19:41:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:41:53 INFO  time: compiled sample in 73ms[0m
Jan 01, 2023 7:42:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1186
2023.01.01 19:42:13 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:42:13 INFO  time: compiled sample in 81ms[0m
2023.01.01 19:42:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:42:15 INFO  time: compiled sample in 73ms[0m
2023.01.01 19:42:21 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:42:21 INFO  time: compiled sample in 75ms[0m
2023.01.01 19:42:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:42:24 INFO  time: compiled sample in 67ms[0m
2023.01.01 19:42:35 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:42:35 INFO  time: compiled sample in 75ms[0m
2023.01.01 19:42:55 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:42:55 INFO  time: compiled sample in 78ms[0m
2023.01.01 19:43:06 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:43:06 INFO  time: compiled sample in 76ms[0m
2023.01.01 19:43:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:43:26 INFO  time: compiled sample in 0.43s[0m
2023.01.01 19:43:33 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:43:33 INFO  time: compiled sample in 0.37s[0m
2023.01.01 19:43:37 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 45m 47.245s)[0m
2023.01.01 19:43:37 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:43:37 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:43:37 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:43:38 INFO  Trying to attach to remote debuggee VM localhost:54611 .[0m
2023.01.01 19:43:38 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:43:38 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:43:42 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:43:42 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:43:42 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:43:42 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:43:42 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:43:43 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:43:42 INFO  Closing debug server tcp://0.0.0.0:44943[0m
2023.01.01 19:44:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:44:03 INFO  time: compiled sample in 0.4s[0m
2023.01.01 19:44:08 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:44:08 INFO  time: compiled sample in 0.37s[0m
2023.01.01 19:44:11 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 46m 21.325s)[0m
2023.01.01 19:44:11 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:44:11 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:44:11 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:44:12 INFO  Trying to attach to remote debuggee VM localhost:56115 .[0m
2023.01.01 19:44:12 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:44:13 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:44:12 INFO  Closing debug server tcp://0.0.0.0:34415[0m
2023.01.01 19:44:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:44:54 INFO  time: compiled sample in 0.4s[0m
2023.01.01 19:45:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:45:39 INFO  time: compiled sample in 0.38s[0m
2023.01.01 19:46:18 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:46:18 INFO  time: compiled sample in 78ms[0m
2023.01.01 19:46:20 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:46:20 INFO  time: compiled sample in 77ms[0m
2023.01.01 19:46:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:46:26 INFO  time: compiled sample in 80ms[0m
2023.01.01 19:47:09 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:47:09 INFO  time: compiled sample in 71ms[0m
2023.01.01 19:47:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:47:17 INFO  time: compiled sample in 0.41s[0m
2023.01.01 19:47:18 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:47:18 INFO  time: compiled sample in 0.42s[0m
2023.01.01 19:47:50 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:47:50 INFO  time: compiled sample in 0.36s[0m
2023.01.01 19:48:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:48:36 INFO  time: compiled sample in 0.4s[0m
2023.01.01 19:48:41 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 50m 51.41s)[0m
2023.01.01 19:48:41 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:48:41 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:48:41 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:48:42 INFO  Trying to attach to remote debuggee VM localhost:50019 .[0m
2023.01.01 19:48:42 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:48:42 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:48:46 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:48:46 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:48:46 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:48:46 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:48:46 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:48:48 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:48:48 INFO  Closing debug server tcp://0.0.0.0:46797[0m
2023.01.01 19:51:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:51:44 INFO  time: compiled sample in 0.54s[0m
2023.01.01 19:52:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:52:19 INFO  time: compiled sample in 0.12s[0m
2023.01.01 19:52:35 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:52:35 INFO  time: compiled sample in 94ms[0m
2023.01.01 19:52:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:52:56 INFO  time: compiled sample in 0.45s[0m
2023.01.01 19:53:05 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 55m 15.538s)[0m
2023.01.01 19:53:05 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:53:05 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:53:05 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:53:07 INFO  Trying to attach to remote debuggee VM localhost:34003 .[0m
2023.01.01 19:53:07 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:53:07 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:53:10 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:53:10 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:53:10 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:53:10 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:53:10 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:54:30 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:54:30 INFO  time: compiled sample in 87ms[0m
2023.01.01 19:54:35 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:54:35 INFO  time: compiled sample in 73ms[0m
2023.01.01 19:54:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:54:37 INFO  time: compiled sample in 0.18s[0m
2023.01.01 19:55:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:55:41 INFO  time: compiled sample in 85ms[0m
2023.01.01 19:55:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:55:41 INFO  time: compiled sample in 43ms[0m
2023.01.01 19:56:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:56:00 INFO  time: compiled sample in 86ms[0m
2023.01.01 19:56:06 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:56:06 INFO  time: compiled sample in 66ms[0m
2023.01.01 19:56:10 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:56:10 INFO  time: compiled sample in 52ms[0m
2023.01.01 19:56:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:56:14 INFO  time: compiled sample in 0.49s[0m
2023.01.01 19:56:17 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 58m 27.716s)[0m
2023.01.01 19:56:17 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:56:17 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:56:18 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:56:19 INFO  Trying to attach to remote debuggee VM localhost:35919 .[0m
2023.01.01 19:56:19 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:56:19 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:56:22 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:56:22 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:56:22 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:56:22 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:56:22 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:56:24 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (172.25.125.240 executor driver): java.lang.ArrayIndexOutOfBoundsException: Index 2 out of bounds for length 2[0m
2023.01.01 19:56:24 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$2(DominanceQueries.scala:27)[0m
2023.01.01 19:56:24 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$2$adapted(DominanceQueries.scala:27)[0m
2023.01.01 19:56:24 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 19:56:24 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 19:56:24 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 19:56:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 19:56:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 19:56:24 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 19:56:24 ERROR [0m
2023.01.01 19:56:24 ERROR Driver stacktrace:[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 19:56:24 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 19:56:24 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$1(RDD.scala:1003)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDD.foreach(RDD.scala:1001)[0m
2023.01.01 19:56:24 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:27)[0m
2023.01.01 19:56:24 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 19:56:24 ERROR Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 2 out of bounds for length 2[0m
2023.01.01 19:56:24 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$2(DominanceQueries.scala:27)[0m
2023.01.01 19:56:24 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$2$adapted(DominanceQueries.scala:27)[0m
2023.01.01 19:56:24 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 19:56:24 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 19:56:24 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 19:56:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 19:56:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 19:56:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 19:56:24 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 19:56:24 INFO  Closing debug server tcp://0.0.0.0:45529[0m
2023.01.01 19:56:24 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:56:39 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:56:39 INFO  Closing debug server tcp://0.0.0.0:41181[0m
2023.01.01 19:56:42 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 58m 52.554s)[0m
2023.01.01 19:56:42 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:56:42 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:56:42 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:56:43 INFO  Trying to attach to remote debuggee VM localhost:45571 .[0m
2023.01.01 19:56:43 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:56:43 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:56:47 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:56:47 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:56:47 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:56:47 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:56:47 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:56:48 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (172.25.125.240 executor driver): java.lang.ArrayIndexOutOfBoundsException: Index 2 out of bounds for length 2[0m
2023.01.01 19:56:48 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$2(DominanceQueries.scala:27)[0m
2023.01.01 19:56:48 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$2$adapted(DominanceQueries.scala:27)[0m
2023.01.01 19:56:48 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 19:56:48 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 19:56:48 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 19:56:48 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 19:56:48 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 19:56:48 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 19:56:48 ERROR [0m
2023.01.01 19:56:48 ERROR Driver stacktrace:[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 19:56:48 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 19:56:48 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$1(RDD.scala:1003)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDD.foreach(RDD.scala:1001)[0m
2023.01.01 19:56:48 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:27)[0m
2023.01.01 19:56:48 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 19:56:48 ERROR Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 2 out of bounds for length 2[0m
2023.01.01 19:56:48 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$2(DominanceQueries.scala:27)[0m
2023.01.01 19:56:48 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$2$adapted(DominanceQueries.scala:27)[0m
2023.01.01 19:56:48 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 19:56:48 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 19:56:48 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 19:56:48 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 19:56:48 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 19:56:48 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 19:56:48 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 19:56:48 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:56:48 INFO  Closing debug server tcp://0.0.0.0:42503[0m
2023.01.01 19:57:02 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:57:02 INFO  time: compiled sample in 0.46s[0m
2023.01.01 19:57:08 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 59m 18.066s)[0m
2023.01.01 19:57:08 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:57:08 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:57:08 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:57:09 INFO  Trying to attach to remote debuggee VM localhost:54713 .[0m
2023.01.01 19:57:09 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:57:09 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:57:12 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:57:12 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:57:12 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:57:12 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:57:12 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:57:14 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:57:14 INFO  Closing debug server tcp://0.0.0.0:38539[0m
2023.01.01 19:58:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 19:58:59 INFO  time: compiled sample in 0.42s[0m
2023.01.01 19:59:07 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 1m 17.069s)[0m
2023.01.01 19:59:07 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 19:59:07 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 19:59:07 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:59:08 INFO  Trying to attach to remote debuggee VM localhost:41959 .[0m
2023.01.01 19:59:08 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 19:59:08 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 19:59:11 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 19:59:11 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 19:59:11 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 19:59:11 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 19:59:11 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 19:59:13 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 19:59:13 INFO  Closing debug server tcp://0.0.0.0:41649[0m
2023.01.01 20:01:16 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:01:16 INFO  time: compiled sample in 0.46s[0m
2023.01.01 20:04:20 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:04:20 INFO  time: compiled sample in 0.48s[0m
2023.01.01 20:04:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:04:43 INFO  time: compiled sample in 0.47s[0m
2023.01.01 20:06:55 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:06:55 INFO  time: compiled sample in 96ms[0m
something's wrong: no file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala in org.apache.spark.rdd.RDD[<error>]RangePosition(file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala, 921, 921, 929)
something's wrong: no file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala in org.apache.spark.rdd.RDD[<error>]RangePosition(file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala, 921, 921, 931)
2023.01.01 20:07:02 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:07:02 INFO  time: compiled sample in 81ms[0m
2023.01.01 20:07:06 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:07:06 INFO  time: compiled sample in 0.49s[0m
2023.01.01 20:08:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:08:07 INFO  time: compiled sample in 89ms[0m
2023.01.01 20:08:20 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:08:20 INFO  time: compiled sample in 0.14s[0m
2023.01.01 20:08:20 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:08:20 INFO  time: compiled sample in 43ms[0m
2023.01.01 20:08:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:08:29 INFO  time: compiled sample in 90ms[0m
2023.01.01 20:09:28 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:09:28 INFO  time: compiled sample in 0.1s[0m
2023.01.01 20:10:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:10:12 INFO  time: compiled sample in 0.11s[0m
2023.01.01 20:10:20 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:10:20 INFO  time: compiled sample in 0.1s[0m
2023.01.01 20:10:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:10:44 INFO  time: compiled sample in 0.11s[0m
2023.01.01 20:11:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:11:07 INFO  time: compiled sample in 0.61s[0m
2023.01.01 20:11:13 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 13m 23.641s)[0m
2023.01.01 20:11:13 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:11:13 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:11:14 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:11:15 INFO  Trying to attach to remote debuggee VM localhost:48977 .[0m
2023.01.01 20:11:15 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:11:15 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:11:18 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:11:18 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:11:18 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:11:18 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:11:18 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:11:20 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:11:20 INFO  Closing debug server tcp://0.0.0.0:43901[0m
2023.01.01 20:12:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:12:17 INFO  time: compiled sample in 0.53s[0m
2023.01.01 20:12:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:12:53 INFO  time: compiled sample in 0.49s[0m
2023.01.01 20:13:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:13:00 INFO  time: compiled sample in 0.45s[0m
2023.01.01 20:13:13 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:13:13 INFO  time: compiled sample in 0.46s[0m
2023.01.01 20:13:35 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:13:35 INFO  time: compiled sample in 0.46s[0m
2023.01.01 20:14:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:14:07 INFO  time: compiled sample in 0.43s[0m
2023.01.01 20:14:16 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:14:16 INFO  time: compiled sample in 0.43s[0m
Jan 01, 2023 8:21:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4352
2023.01.01 20:22:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:22:03 INFO  time: compiled sample in 0.16s[0m
2023.01.01 20:22:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:22:12 INFO  time: compiled sample in 0.46s[0m
2023.01.01 20:23:01 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:23:01 INFO  time: compiled sample in 0.44s[0m
2023.01.01 20:23:02 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:23:02 INFO  time: compiled sample in 0.43s[0m
2023.01.01 20:23:02 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:23:02 INFO  time: compiled sample in 0.14s[0m
2023.01.01 20:23:04 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:23:04 INFO  time: compiled sample in 0.13s[0m
2023.01.01 20:23:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:23:25 INFO  time: compiled sample in 95ms[0m
2023.01.01 20:23:46 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:23:46 INFO  time: compiled sample in 0.43s[0m
2023.01.01 20:23:50 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 25m 59.955s)[0m
2023.01.01 20:23:50 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:23:50 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:23:50 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:23:51 INFO  Trying to attach to remote debuggee VM localhost:44687 .[0m
2023.01.01 20:23:51 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:23:51 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:23:55 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:23:55 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:23:55 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:23:55 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:23:55 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:23:56 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:23:56 INFO  Closing debug server tcp://0.0.0.0:36813[0m
2023.01.01 20:24:10 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:24:10 INFO  time: compiled sample in 0.42s[0m
2023.01.01 20:24:15 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 26m 25.455s)[0m
2023.01.01 20:24:15 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:24:15 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:24:15 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:24:16 INFO  Trying to attach to remote debuggee VM localhost:56417 .[0m
2023.01.01 20:24:16 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:24:16 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:24:20 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:24:20 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:24:20 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:24:20 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:24:20 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:24:21 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:24:21 INFO  Closing debug server tcp://0.0.0.0:42709[0m
2023.01.01 20:24:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:24:53 INFO  time: compiled sample in 94ms[0m
2023.01.01 20:25:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:25:00 INFO  time: compiled sample in 0.41s[0m
2023.01.01 20:26:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:26:19 INFO  time: compiled sample in 62ms[0m
2023.01.01 20:26:21 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:26:21 INFO  time: compiled sample in 0.41s[0m
Jan 01, 2023 8:26:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4923
2023.01.01 20:26:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:26:31 INFO  time: compiled sample in 0.38s[0m
2023.01.01 20:26:52 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:26:52 INFO  time: compiled sample in 59ms[0m
2023.01.01 20:27:18 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:27:18 INFO  time: compiled sample in 0.63s[0m
2023.01.01 20:27:22 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 29m 32.673s)[0m
2023.01.01 20:27:22 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:27:22 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:27:23 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:27:23 INFO  Trying to attach to remote debuggee VM localhost:56907 .[0m
2023.01.01 20:27:23 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:27:23 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:27:27 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:27:27 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:27:27 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:27:27 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:27:27 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:27:28 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:27:28 INFO  Closing debug server tcp://0.0.0.0:36551[0m
2023.01.01 20:27:49 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:27:49 INFO  time: compiled sample in 0.41s[0m
2023.01.01 20:27:53 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 30m 3.535s)[0m
2023.01.01 20:27:53 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:27:53 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:27:53 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:27:54 INFO  Trying to attach to remote debuggee VM localhost:40209 .[0m
2023.01.01 20:27:54 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:27:54 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:27:58 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:27:58 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:27:58 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:27:58 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:27:58 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:27:59 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:27:59 INFO  Closing debug server tcp://0.0.0.0:45887[0m
2023.01.01 20:28:42 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:28:42 INFO  time: compiled sample in 0.43s[0m
2023.01.01 20:29:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:29:15 INFO  time: compiled sample in 0.38s[0m
2023.01.01 20:29:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:29:36 INFO  time: compiled sample in 0.4s[0m
2023.01.01 20:29:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:29:41 INFO  time: compiled sample in 0.38s[0m
2023.01.01 20:30:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:30:03 INFO  time: compiled sample in 0.41s[0m
2023.01.01 20:30:10 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 32m 19.826s)[0m
2023.01.01 20:30:10 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:30:10 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:30:10 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:30:11 INFO  Trying to attach to remote debuggee VM localhost:45335 .[0m
2023.01.01 20:30:11 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:30:11 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:30:14 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:30:14 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:30:14 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:30:14 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:30:14 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:30:16 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:30:16 INFO  Closing debug server tcp://0.0.0.0:35777[0m
2023.01.01 20:30:42 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:30:42 INFO  time: compiled sample in 0.44s[0m
2023.01.01 20:30:47 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 32m 56.98s)[0m
2023.01.01 20:30:47 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:30:47 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:30:47 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:30:48 INFO  Trying to attach to remote debuggee VM localhost:50341 .[0m
2023.01.01 20:30:48 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:30:48 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:30:51 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:30:51 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:30:51 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:30:51 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:30:51 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:30:53 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:30:53 INFO  Closing debug server tcp://0.0.0.0:46865[0m
2023.01.01 20:30:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:30:59 INFO  time: compiled sample in 0.41s[0m
2023.01.01 20:31:03 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 33m 13.041s)[0m
2023.01.01 20:31:03 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:31:03 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:31:03 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:31:04 INFO  Trying to attach to remote debuggee VM localhost:49335 .[0m
2023.01.01 20:31:04 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:31:04 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:31:08 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:31:08 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:31:08 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:31:08 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:31:08 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:31:09 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:31:09 INFO  Closing debug server tcp://0.0.0.0:36251[0m
2023.01.01 20:31:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:31:39 INFO  time: compiled sample in 0.42s[0m
2023.01.01 20:31:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:31:43 INFO  time: compiled sample in 0.57s[0m
2023.01.01 20:31:52 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 1h 34m 2.028s)[0m
2023.01.01 20:31:52 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 20:31:52 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 20:31:52 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:31:53 INFO  Trying to attach to remote debuggee VM localhost:34875 .[0m
2023.01.01 20:31:53 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 20:31:53 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 20:31:57 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 20:31:57 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 20:31:57 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 20:31:57 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 20:31:57 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 20:31:58 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 20:31:58 INFO  Closing debug server tcp://0.0.0.0:45233[0m
2023.01.01 20:32:10 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:32:10 INFO  time: compiled sample in 0.4s[0m
2023.01.01 20:32:22 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:32:22 INFO  time: compiled sample in 0.37s[0m
2023.01.01 20:32:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:32:25 INFO  time: compiled sample in 0.43s[0m
2023.01.01 20:39:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:39:17 INFO  time: compiled sample in 0.53s[0m
2023.01.01 20:40:06 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:06 INFO  time: compiled sample in 0.12s[0m
2023.01.01 20:40:09 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:09 INFO  time: compiled sample in 0.12s[0m
2023.01.01 20:40:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:15 INFO  time: compiled sample in 94ms[0m
2023.01.01 20:40:34 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:34 INFO  time: compiled sample in 93ms[0m
2023.01.01 20:40:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:39 INFO  time: compiled sample in 95ms[0m
2023.01.01 20:40:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:44 INFO  time: compiled sample in 97ms[0m
2023.01.01 20:40:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:44 INFO  time: compiled sample in 57ms[0m
2023.01.01 20:40:57 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:57 INFO  time: compiled sample in 0.12s[0m
2023.01.01 20:40:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:40:59 INFO  time: compiled sample in 84ms[0m
2023.01.01 20:41:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:41:24 INFO  time: compiled sample in 90ms[0m
2023.01.01 20:41:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:41:29 INFO  time: compiled sample in 89ms[0m
2023.01.01 20:41:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:41:31 INFO  time: compiled sample in 80ms[0m
2023.01.01 20:41:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:41:56 INFO  time: compiled sample in 91ms[0m
2023.01.01 20:41:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:41:56 INFO  time: compiled sample in 46ms[0m
2023.01.01 20:44:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:44:39 INFO  time: compiled sample in 98ms[0m
2023.01.01 20:44:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:44:39 INFO  time: compiled sample in 54ms[0m
2023.01.01 20:44:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:44:40 INFO  time: compiled sample in 46ms[0m
2023.01.01 20:44:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:44:41 INFO  time: compiled sample in 51ms[0m
2023.01.01 20:44:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:44:42 INFO  time: compiled sample in 58ms[0m
2023.01.01 20:48:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:48:54 INFO  time: compiled sample in 0.1s[0m
2023.01.01 20:49:05 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:49:05 INFO  time: compiled sample in 83ms[0m
2023.01.01 20:49:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:49:07 INFO  time: compiled sample in 83ms[0m
2023.01.01 20:49:13 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:49:13 INFO  time: compiled sample in 83ms[0m
2023.01.01 20:49:13 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:49:13 INFO  time: compiled sample in 45ms[0m
2023.01.01 20:49:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:49:15 INFO  time: compiled sample in 42ms[0m
2023.01.01 20:59:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:59:00 INFO  time: compiled sample in 99ms[0m
2023.01.01 20:59:04 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:59:04 INFO  time: compiled sample in 98ms[0m
2023.01.01 20:59:47 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:59:47 INFO  time: compiled sample in 0.23s[0m
2023.01.01 20:59:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:59:56 INFO  time: compiled sample in 0.13s[0m
2023.01.01 20:59:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 20:59:59 INFO  time: compiled sample in 0.13s[0m
2023.01.01 21:00:50 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:00:50 INFO  time: compiled sample in 0.14s[0m
2023.01.01 21:00:57 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:00:57 INFO  time: compiled sample in 62ms[0m
2023.01.01 21:01:10 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:01:10 INFO  time: compiled sample in 0.12s[0m
2023.01.01 21:01:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:01:14 INFO  time: compiled sample in 0.12s[0m
2023.01.01 21:01:27 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:01:27 INFO  time: compiled sample in 57ms[0m
2023.01.01 21:01:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:01:29 INFO  time: compiled sample in 0.17s[0m
2023.01.01 21:01:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:01:36 INFO  time: compiled sample in 0.12s[0m
2023.01.01 21:01:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:01:59 INFO  time: compiled sample in 88ms[0m
2023.01.01 21:02:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:02:19 INFO  time: compiled sample in 0.12s[0m
2023.01.01 21:02:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:02:31 INFO  time: compiled sample in 0.11s[0m
Jan 01, 2023 9:02:44 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6675
2023.01.01 21:02:46 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:02:46 INFO  time: compiled sample in 0.16s[0m
2023.01.01 21:03:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:03:39 INFO  time: compiled sample in 71ms[0m
2023.01.01 21:03:50 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:03:50 INFO  time: compiled sample in 72ms[0m
2023.01.01 21:03:52 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:03:52 INFO  time: compiled sample in 55ms[0m
2023.01.01 21:03:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:03:54 INFO  time: compiled sample in 56ms[0m
2023.01.01 21:03:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:03:54 INFO  time: compiled sample in 15ms[0m
2023.01.01 21:04:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:04:12 INFO  time: compiled sample in 57ms[0m
2023.01.01 21:04:16 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:04:16 INFO  time: compiled sample in 53ms[0m
2023.01.01 21:04:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:04:23 INFO  time: compiled sample in 55ms[0m
2023.01.01 21:04:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:04:36 INFO  time: compiled sample in 0.47s[0m
2023.01.01 21:04:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:04:39 INFO  time: compiled sample in 0.44s[0m
2023.01.01 21:04:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:04:59 INFO  time: compiled sample in 0.42s[0m
2023.01.01 21:05:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:05:53 INFO  time: compiled sample in 0.39s[0m
2023.01.01 21:06:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:06:07 INFO  time: compiled sample in 0.38s[0m
2023.01.01 21:06:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:06:36 INFO  time: compiled sample in 0.4s[0m
2023.01.01 21:06:42 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:06:42 INFO  time: compiled sample in 0.38s[0m
2023.01.01 21:10:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:10:31 INFO  time: compiled sample in 0.12s[0m
2023.01.01 21:10:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:10:39 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:10:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:10:44 INFO  time: compiled sample in 94ms[0m
2023.01.01 21:10:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:10:53 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:10:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:10:56 INFO  time: compiled sample in 97ms[0m
2023.01.01 21:10:57 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:10:57 INFO  time: compiled sample in 98ms[0m
2023.01.01 21:11:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:14 INFO  time: compiled sample in 89ms[0m
2023.01.01 21:11:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:14 INFO  time: compiled sample in 50ms[0m
2023.01.01 21:11:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:15 INFO  time: compiled sample in 69ms[0m
2023.01.01 21:11:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:15 INFO  time: compiled sample in 52ms[0m
2023.01.01 21:11:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:17 INFO  time: compiled sample in 49ms[0m
2023.01.01 21:11:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:17 INFO  time: compiled sample in 47ms[0m
2023.01.01 21:11:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:23 INFO  time: compiled sample in 83ms[0m
2023.01.01 21:11:27 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:27 INFO  time: compiled sample in 83ms[0m
2023.01.01 21:11:45 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:11:45 INFO  time: compiled sample in 92ms[0m
2023.01.01 21:12:06 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:12:06 INFO  time: compiled sample in 86ms[0m
2023.01.01 21:15:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:15:43 INFO  time: compiled sample in 0.58s[0m
2023.01.01 21:16:34 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:16:34 INFO  time: compiled sample in 0.56s[0m
2023.01.01 21:17:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:17:59 INFO  time: compiled sample in 0.57s[0m
Jan 01, 2023 9:18:02 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7671
2023.01.01 21:18:13 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:18:13 INFO  time: compiled sample in 0.54s[0m
2023.01.01 21:18:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:18:17 INFO  time: compiled sample in 0.5s[0m
2023.01.01 21:18:21 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:18:21 INFO  time: compiled sample in 0.54s[0m
2023.01.01 21:18:46 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:18:46 INFO  time: compiled sample in 0.48s[0m
2023.01.01 21:19:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:19:24 INFO  time: compiled sample in 1.14s[0m
2023.01.01 21:19:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:19:54 INFO  time: compiled sample in 0.54s[0m
2023.01.01 21:22:30 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:22:30 INFO  time: compiled sample in 93ms[0m
2023.01.01 21:22:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:22:37 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:22:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:22:56 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:23:01 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:23:01 INFO  time: compiled sample in 96ms[0m
2023.01.01 21:23:11 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:23:11 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:23:18 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:23:18 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:23:21 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:23:21 INFO  time: compiled sample in 95ms[0m
2023.01.01 21:23:21 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:23:21 INFO  time: compiled sample in 49ms[0m
2023.01.01 21:23:22 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:23:22 INFO  time: compiled sample in 52ms[0m
2023.01.01 21:23:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:23:24 INFO  time: compiled sample in 81ms[0m
2023.01.01 21:23:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:23:44 INFO  time: compiled sample in 98ms[0m
2023.01.01 21:25:04 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:25:04 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:25:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:25:23 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:26:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:26:03 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:26:05 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:26:05 INFO  time: compiled sample in 97ms[0m
2023.01.01 21:27:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:27:39 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:28:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:28:15 INFO  time: compiled sample in 98ms[0m
2023.01.01 21:28:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:28:17 INFO  time: compiled sample in 98ms[0m
2023.01.01 21:28:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:28:26 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:30:52 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:30:52 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:30:52 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:30:52 INFO  time: compiled sample in 46ms[0m
2023.01.01 21:30:52 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:30:53 INFO  time: compiled sample in 52ms[0m
2023.01.01 21:38:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:19 INFO  time: compiled sample in 0.12s[0m
2023.01.01 21:38:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:19 INFO  time: compiled sample in 50ms[0m
2023.01.01 21:38:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:19 INFO  time: compiled sample in 51ms[0m
2023.01.01 21:38:21 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:21 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:38:21 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:21 INFO  time: compiled sample in 60ms[0m
2023.01.01 21:38:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:23 INFO  time: compiled sample in 50ms[0m
2023.01.01 21:38:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:23 INFO  time: compiled sample in 59ms[0m
2023.01.01 21:38:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:24 INFO  time: compiled sample in 60ms[0m
2023.01.01 21:38:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:24 INFO  time: compiled sample in 58ms[0m
2023.01.01 21:38:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:24 INFO  time: compiled sample in 60ms[0m
2023.01.01 21:38:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:26 INFO  time: compiled sample in 59ms[0m
2023.01.01 21:38:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:44 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:38:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:44 INFO  time: compiled sample in 47ms[0m
2023.01.01 21:38:45 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:45 INFO  time: compiled sample in 53ms[0m
2023.01.01 21:38:45 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:45 INFO  time: compiled sample in 63ms[0m
2023.01.01 21:38:46 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:38:46 INFO  time: compiled sample in 46ms[0m
2023.01.01 21:41:58 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:41:58 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:42:11 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:42:11 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:42:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:42:14 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:42:30 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:42:30 INFO  time: compiled sample in 98ms[0m
2023.01.01 21:42:35 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:42:35 INFO  time: compiled sample in 0.12s[0m
2023.01.01 21:42:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:42:36 INFO  time: compiled sample in 96ms[0m
2023.01.01 21:42:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:42:54 INFO  time: compiled sample in 84ms[0m
2023.01.01 21:43:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:43:00 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:43:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:43:03 INFO  time: compiled sample in 93ms[0m
2023.01.01 21:43:05 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:43:05 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:43:13 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:43:13 INFO  time: compiled sample in 86ms[0m
2023.01.01 21:43:20 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:43:20 INFO  time: compiled sample in 87ms[0m
2023.01.01 21:44:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:44:07 INFO  time: compiled sample in 96ms[0m
2023.01.01 21:44:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:44:12 INFO  time: compiled sample in 0.1s[0m
2023.01.01 21:44:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:44:15 INFO  time: compiled sample in 99ms[0m
2023.01.01 21:44:35 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:44:35 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:44:35 INFO  time: compiled sample in 0.49s[0m
2023.01.01 21:44:51 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:44:51 INFO  time: compiled sample in 97ms[0m
Jan 01, 2023 9:44:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8764
Jan 01, 2023 9:44:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8769
2023.01.01 21:44:55 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:44:55 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:44:55 INFO  time: compiled sample in 0.56s[0m
2023.01.01 21:45:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:45:19 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:45:19 INFO  time: compiled sample in 0.53s[0m
2023.01.01 21:45:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:45:23 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:45:23 INFO  time: compiled sample in 0.52s[0m
2023.01.01 21:45:27 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:45:27 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:45:27 INFO  time: compiled sample in 0.5s[0m
2023.01.01 21:45:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:45:59 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:45:59 INFO  time: compiled sample in 0.49s[0m
2023.01.01 21:46:08 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 2h 48m 18.757s)[0m
2023.01.01 21:46:08 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 21:46:08 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 21:46:09 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:46:11 INFO  Trying to attach to remote debuggee VM localhost:49389 .[0m
2023.01.01 21:46:11 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 21:46:11 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 21:46:14 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 21:46:14 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 21:46:14 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 21:46:14 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 21:46:14 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 21:46:16 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (172.25.125.240 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:46:16 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:46:16 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:46:16 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:53)[0m
2023.01.01 21:46:16 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:52)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:46:16 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:46:16 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:46:16 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:46:16 ERROR [0m
2023.01.01 21:46:16 ERROR Driver stacktrace:[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 21:46:16 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$1(RDD.scala:1003)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.foreach(RDD.scala:1001)[0m
2023.01.01 21:46:16 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:59)[0m
2023.01.01 21:46:16 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 21:46:16 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:46:16 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:46:16 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:46:16 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:53)[0m
2023.01.01 21:46:16 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:52)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:46:16 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:46:16 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:46:16 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:46:16 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:46:16 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:46:16 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:46:16 INFO  Closing debug server tcp://0.0.0.0:38671[0m
2023.01.01 21:47:50 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:47:50 INFO  time: compiled sample in 93ms[0m
2023.01.01 21:48:01 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:48:01 INFO  time: compiled sample in 0.13s[0m
2023.01.01 21:48:02 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:48:02 INFO  time: compiled sample in 0.11s[0m
2023.01.01 21:48:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:48:24 INFO  time: compiled sample in 98ms[0m
2023.01.01 21:48:43 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:43 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:43 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:43 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:51 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:51 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:51 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:52 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:51 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:52 INFO  file:///home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala:59:9: stale bloop error: value flatten is not a member of org.apache.spark.rdd.RDD[DominanceQueries.DominanceQueries.Point]
        nonDominatedPointsRDD.flatten.foreach(println)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
2023.01.01 21:48:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:48:53 INFO  time: compiled sample in 64ms[0m
2023.01.01 21:48:57 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:48:57 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:48:57 INFO  time: compiled sample in 0.5s[0m
2023.01.01 21:48:58 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:48:58 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:48:58 INFO  time: compiled sample in 0.18s[0m
2023.01.01 21:49:11 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 2h 51m 21.657s)[0m
2023.01.01 21:49:11 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 21:49:12 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 21:49:12 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:49:13 INFO  Trying to attach to remote debuggee VM localhost:57939 .[0m
2023.01.01 21:49:13 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 21:49:13 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 21:49:16 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 21:49:16 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 21:49:16 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 21:49:16 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 21:49:16 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 21:49:17 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (172.25.125.240 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:49:17 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:49:17 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:49:17 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:53)[0m
2023.01.01 21:49:17 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:52)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:49:17 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:49:17 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:49:17 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:49:17 ERROR [0m
2023.01.01 21:49:17 ERROR Driver stacktrace:[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 21:49:17 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$1(RDD.scala:1003)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.foreach(RDD.scala:1001)[0m
2023.01.01 21:49:17 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:59)[0m
2023.01.01 21:49:17 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 21:49:17 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:49:17 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:49:17 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:49:17 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:53)[0m
2023.01.01 21:49:17 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:52)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:49:17 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:49:17 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:49:17 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:49:17 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:49:17 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:49:17 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:49:17 INFO  Closing debug server tcp://0.0.0.0:42687[0m
2023.01.01 21:50:34 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:50:34 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:50:34 INFO  time: compiled sample in 0.51s[0m
2023.01.01 21:50:48 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:50:48 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:50:48 INFO  time: compiled sample in 0.48s[0m
2023.01.01 21:51:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:51:00 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:51:00 INFO  time: compiled sample in 0.49s[0m
2023.01.01 21:51:19 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 2h 53m 29.142s)[0m
2023.01.01 21:51:19 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 21:51:19 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 21:51:19 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:51:20 INFO  Trying to attach to remote debuggee VM localhost:40129 .[0m
2023.01.01 21:51:20 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 21:51:20 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 21:51:24 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 21:51:24 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 21:51:24 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 21:51:24 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 21:51:24 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 21:51:25 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (172.25.125.240 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:51:25 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:51:25 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:51:25 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:53)[0m
2023.01.01 21:51:25 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:52)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:51:25 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:51:25 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:51:25 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:51:25 ERROR [0m
2023.01.01 21:51:25 ERROR Driver stacktrace:[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 21:51:25 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$1(RDD.scala:1003)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.foreach(RDD.scala:1001)[0m
2023.01.01 21:51:25 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:58)[0m
2023.01.01 21:51:25 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 21:51:25 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:51:25 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:51:25 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:51:25 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:53)[0m
2023.01.01 21:51:25 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:52)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:51:25 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:51:25 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:51:25 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:51:25 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:51:25 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:51:25 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:51:25 INFO  Closing debug server tcp://0.0.0.0:34703[0m
2023.01.01 21:52:58 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:52:58 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:52:58 INFO  time: compiled sample in 0.53s[0m
2023.01.01 21:53:34 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:53:34 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:53:34 INFO  time: compiled sample in 0.51s[0m
2023.01.01 21:53:53 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 2h 56m 3.221s)[0m
2023.01.01 21:53:53 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 21:53:53 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 21:53:53 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:53:54 INFO  Trying to attach to remote debuggee VM localhost:47893 .[0m
2023.01.01 21:53:54 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 21:53:54 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 21:53:58 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 21:53:58 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 21:53:58 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 21:53:58 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 21:53:58 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 21:53:59 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (172.25.125.240 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:53:59 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:53:59 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:53:59 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:51)[0m
2023.01.01 21:53:59 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:50)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:53:59 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:53:59 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:53:59 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:53:59 ERROR [0m
2023.01.01 21:53:59 ERROR Driver stacktrace:[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 21:53:59 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$1(RDD.scala:1003)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.foreach(RDD.scala:1001)[0m
2023.01.01 21:53:59 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:56)[0m
2023.01.01 21:53:59 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 21:53:59 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:53:59 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:53:59 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:53:59 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:51)[0m
2023.01.01 21:53:59 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:50)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:53:59 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:53:59 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:53:59 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:53:59 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:53:59 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:53:59 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:53:59 INFO  Closing debug server tcp://0.0.0.0:36535[0m
2023.01.01 21:55:35 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:55:35 WARN  1 deprecation (since 2.13.0); re-run with -deprecation for details[0m
2023.01.01 21:55:35 INFO  time: compiled sample in 0.5s[0m
2023.01.01 21:55:40 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 2h 57m 50.454s)[0m
2023.01.01 21:55:40 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 21:55:40 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 21:55:40 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:55:41 INFO  Trying to attach to remote debuggee VM localhost:60261 .[0m
2023.01.01 21:55:41 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 21:55:41 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 21:55:45 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 21:55:45 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 21:55:45 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 21:55:45 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 21:55:45 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 21:55:46 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (172.25.125.240 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:55:46 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:55:46 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:55:46 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:51)[0m
2023.01.01 21:55:46 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:50)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:55:46 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:55:46 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:55:46 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:55:46 ERROR [0m
2023.01.01 21:55:46 ERROR Driver stacktrace:[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 21:55:46 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$1(RDD.scala:1003)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.foreach(RDD.scala:1001)[0m
2023.01.01 21:55:46 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:56)[0m
2023.01.01 21:55:46 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 21:55:46 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 21:55:46 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 21:55:46 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 21:55:46 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:51)[0m
2023.01.01 21:55:46 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3$adapted(DominanceQueries.scala:50)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:479)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573)[0m
2023.01.01 21:55:46 ERROR 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1300)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2(RDD.scala:1003)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$foreach$2$adapted(RDD.scala:1003)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 21:55:46 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 21:55:46 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 21:55:46 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 21:55:46 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 21:55:46 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 21:55:46 INFO  Closing debug server tcp://0.0.0.0:36135[0m
2023.01.01 21:58:10 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:58:10 INFO  time: compiled sample in 0.46s[0m
2023.01.01 21:58:27 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:58:27 INFO  time: compiled sample in 89ms[0m
2023.01.01 21:58:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 21:58:59 INFO  time: compiled sample in 93ms[0m
2023.01.01 22:00:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:00:17 INFO  time: compiled sample in 93ms[0m
2023.01.01 22:01:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:01:59 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:01:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:01:59 INFO  time: compiled sample in 0.25s[0m
2023.01.01 22:02:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:02:00 INFO  time: compiled sample in 58ms[0m
2023.01.01 22:02:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:02:00 INFO  time: compiled sample in 54ms[0m
2023.01.01 22:02:02 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:02:02 INFO  time: compiled sample in 53ms[0m
2023.01.01 22:03:46 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:03:46 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:03:46 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:03:46 INFO  time: compiled sample in 50ms[0m
2023.01.01 22:03:47 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:03:47 INFO  time: compiled sample in 51ms[0m
2023.01.01 22:03:47 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:03:47 INFO  time: compiled sample in 54ms[0m
2023.01.01 22:03:48 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:03:48 INFO  time: compiled sample in 57ms[0m
2023.01.01 22:07:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:07:19 INFO  time: compiled sample in 98ms[0m
2023.01.01 22:07:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:07:36 INFO  time: compiled sample in 96ms[0m
2023.01.01 22:08:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:08:43 INFO  time: compiled sample in 0.11s[0m
2023.01.01 22:08:58 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:08:58 INFO  time: compiled sample in 0.12s[0m
2023.01.01 22:08:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:08:59 INFO  time: compiled sample in 45ms[0m
Jan 01, 2023 10:08:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10388
2023.01.01 22:09:09 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:09:09 INFO  time: compiled sample in 96ms[0m
2023.01.01 22:09:16 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:09:16 INFO  time: compiled sample in 91ms[0m
2023.01.01 22:09:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:09:26 INFO  time: compiled sample in 99ms[0m
2023.01.01 22:09:32 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:09:32 INFO  time: compiled sample in 77ms[0m
2023.01.01 22:09:32 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:09:32 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 3h 11m 42.577s)[0m
2023.01.01 22:09:32 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:09:32 INFO  time: compiled sample in 74ms[0m
2023.01.01 22:09:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:09:37 INFO  time: compiled sample in 94ms[0m
2023.01.01 22:09:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:09:43 INFO  time: compiled sample in 89ms[0m
2023.01.01 22:10:08 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:10:08 INFO  time: compiled sample in 98ms[0m
2023.01.01 22:10:08 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:10:08 INFO  time: compiled sample in 52ms[0m
2023.01.01 22:10:18 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:10:18 INFO  time: compiled sample in 84ms[0m
2023.01.01 22:10:33 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:10:33 INFO  time: compiled sample in 83ms[0m
2023.01.01 22:10:58 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:10:58 INFO  time: compiled sample in 83ms[0m
2023.01.01 22:11:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:11:00 INFO  time: compiled sample in 80ms[0m
2023.01.01 22:11:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:11:15 INFO  time: compiled sample in 91ms[0m
2023.01.01 22:11:45 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:11:45 INFO  time: compiled sample in 87ms[0m
2023.01.01 22:11:47 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:11:47 INFO  time: compiled sample in 62ms[0m
2023.01.01 22:11:49 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:11:49 INFO  time: compiled sample in 53ms[0m
2023.01.01 22:11:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:11:59 INFO  time: compiled sample in 86ms[0m
2023.01.01 22:12:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:12:53 INFO  time: compiled sample in 89ms[0m
2023.01.01 22:12:57 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:12:57 INFO  time: compiled sample in 92ms[0m
2023.01.01 22:13:01 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:13:01 INFO  time: compiled sample in 95ms[0m
2023.01.01 22:13:09 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:13:09 INFO  time: compiled sample in 86ms[0m
2023.01.01 22:13:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:13:14 INFO  time: compiled sample in 86ms[0m
2023.01.01 22:13:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:13:17 INFO  time: compiled sample in 89ms[0m
2023.01.01 22:13:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:13:19 INFO  time: compiled sample in 90ms[0m
2023.01.01 22:14:13 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:14:13 INFO  time: compiled sample in 82ms[0m
2023.01.01 22:14:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:14:17 INFO  time: compiled sample in 0.51s[0m
2023.01.01 22:14:31 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 3h 16m 41.576s)[0m
2023.01.01 22:14:31 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 22:14:31 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 22:14:31 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 22:14:32 INFO  Trying to attach to remote debuggee VM localhost:49745 .[0m
2023.01.01 22:14:32 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 22:14:32 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 22:14:36 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 22:14:36 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 22:14:36 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 22:14:36 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 22:14:36 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 22:14:38 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 22:14:38 INFO  Closing debug server tcp://0.0.0.0:34143[0m
2023.01.01 22:15:02 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:15:02 INFO  time: compiled sample in 0.51s[0m
2023.01.01 22:15:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:15:19 INFO  time: compiled sample in 0.5s[0m
2023.01.01 22:17:09 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:17:09 INFO  time: compiled sample in 0.46s[0m
2023.01.01 22:18:51 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:18:51 INFO  time: compiled sample in 0.55s[0m
2023.01.01 22:20:10 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:20:10 INFO  time: compiled sample in 92ms[0m
2023.01.01 22:20:11 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:20:11 INFO  time: compiled sample in 0.27s[0m
2023.01.01 22:20:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:20:40 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:20:48 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:20:48 INFO  time: compiled sample in 88ms[0m
2023.01.01 22:21:06 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:21:06 INFO  time: compiled sample in 88ms[0m
2023.01.01 22:21:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:21:40 INFO  time: compiled sample in 94ms[0m
2023.01.01 22:21:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:21:44 INFO  time: compiled sample in 94ms[0m
2023.01.01 22:22:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:22:03 INFO  time: compiled sample in 0.55s[0m
2023.01.01 22:22:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:22:23 INFO  time: compiled sample in 0.53s[0m
2023.01.01 22:22:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:22:31 INFO  time: compiled sample in 0.47s[0m
2023.01.01 22:22:55 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:22:55 INFO  time: compiled sample in 0.52s[0m
2023.01.01 22:23:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:23:12 INFO  time: compiled sample in 0.48s[0m
2023.01.01 22:23:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:23:29 INFO  time: compiled sample in 0.49s[0m
2023.01.01 22:24:13 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:24:13 INFO  time: compiled sample in 0.64s[0m
2023.01.01 22:24:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:24:37 INFO  time: compiled sample in 0.49s[0m
2023.01.01 22:25:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:25:26 WARN  Could not load snapshot text for /home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala[0m
2023.01.01 22:25:26 WARN  Could not load snapshot text for /home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala[0m
2023.01.01 22:25:25 INFO  time: compiled sample in 0.51s[0m
2023.01.01 22:26:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:26:07 INFO  time: compiled sample in 0.12s[0m
2023.01.01 22:26:09 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:26:09 INFO  time: compiled sample in 97ms[0m
2023.01.01 22:26:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:26:23 INFO  time: compiled sample in 94ms[0m
2023.01.01 22:26:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:26:26 INFO  time: compiled sample in 96ms[0m
2023.01.01 22:26:32 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:26:32 INFO  time: compiled sample in 96ms[0m
2023.01.01 22:26:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:26:43 INFO  time: compiled sample in 90ms[0m
2023.01.01 22:26:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:26:53 INFO  time: compiled sample in 0.11s[0m
2023.01.01 22:27:02 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:27:02 INFO  time: compiled sample in 84ms[0m
2023.01.01 22:27:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:27:07 INFO  time: compiled sample in 0.52s[0m
2023.01.01 22:28:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:28:36 INFO  time: compiled sample in 91ms[0m
2023.01.01 22:28:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:28:54 INFO  time: compiled sample in 86ms[0m
2023.01.01 22:28:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:28:56 INFO  time: compiled sample in 86ms[0m
2023.01.01 22:29:01 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:29:01 INFO  time: compiled sample in 95ms[0m
2023.01.01 22:29:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:29:07 INFO  time: compiled sample in 85ms[0m
2023.01.01 22:29:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:29:12 INFO  time: compiled sample in 94ms[0m
2023.01.01 22:29:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:29:17 INFO  time: compiled sample in 85ms[0m
2023.01.01 22:29:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:29:26 INFO  time: compiled sample in 0.5s[0m
2023.01.01 22:29:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:29:54 INFO  time: compiled sample in 0.47s[0m
2023.01.01 22:30:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:30:40 INFO  time: compiled sample in 0.51s[0m
2023.01.01 22:31:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:31:14 INFO  time: compiled sample in 0.52s[0m
2023.01.01 22:31:19 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 3h 33m 29.656s)[0m
2023.01.01 22:31:19 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 22:31:19 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 22:31:20 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 22:31:21 INFO  Trying to attach to remote debuggee VM localhost:39301 .[0m
2023.01.01 22:31:21 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 22:31:21 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 22:31:24 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 22:31:24 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 22:31:24 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 22:31:24 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 22:31:24 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 22:31:26 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 22:31:26 INFO  Closing debug server tcp://0.0.0.0:39605[0m
2023.01.01 22:31:45 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 3h 33m 55.637s)[0m
2023.01.01 22:31:45 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 22:31:45 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 22:31:46 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 22:31:46 INFO  Trying to attach to remote debuggee VM localhost:45219 .[0m
2023.01.01 22:31:46 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 22:31:46 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 22:31:50 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 22:31:50 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 22:31:50 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 22:31:50 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 22:31:50 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 22:31:51 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 22:31:51 INFO  Closing debug server tcp://0.0.0.0:40499[0m
2023.01.01 22:33:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:33:25 INFO  time: compiled sample in 0.56s[0m
2023.01.01 22:33:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:33:41 INFO  time: compiled sample in 0.47s[0m
2023.01.01 22:33:48 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:33:48 INFO  time: compiled sample in 0.53s[0m
2023.01.01 22:33:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:33:54 INFO  time: compiled sample in 0.51s[0m
2023.01.01 22:34:03 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 3h 36m 12.905s)[0m
2023.01.01 22:34:03 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 22:34:03 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 22:34:03 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 22:34:04 INFO  Trying to attach to remote debuggee VM localhost:41355 .[0m
2023.01.01 22:34:04 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 22:34:04 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 22:34:07 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 22:34:07 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 22:34:07 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 22:34:07 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 22:34:07 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 22:34:09 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 22:34:09 INFO  Closing debug server tcp://0.0.0.0:39919[0m
2023.01.01 22:34:20 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:34:20 INFO  time: compiled sample in 0.51s[0m
2023.01.01 22:39:28 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:39:28 INFO  time: compiled sample in 0.11s[0m
2023.01.01 22:46:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:46:37 INFO  time: compiled sample in 0.11s[0m
2023.01.01 22:46:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:46:43 INFO  time: compiled sample in 99ms[0m
2023.01.01 22:47:22 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:47:22 INFO  time: compiled sample in 91ms[0m
2023.01.01 22:47:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:47:53 INFO  time: compiled sample in 94ms[0m
2023.01.01 22:47:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:47:56 INFO  time: compiled sample in 90ms[0m
2023.01.01 22:48:46 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:48:46 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:49:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:49:14 INFO  time: compiled sample in 0.12s[0m
2023.01.01 22:49:18 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:49:18 INFO  time: compiled sample in 99ms[0m
2023.01.01 22:49:28 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:49:28 INFO  time: compiled sample in 83ms[0m
2023.01.01 22:49:28 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:49:28 INFO  time: compiled sample in 45ms[0m
2023.01.01 22:49:28 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:49:28 INFO  time: compiled sample in 52ms[0m
2023.01.01 22:49:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:49:29 INFO  time: compiled sample in 47ms[0m
2023.01.01 22:49:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:49:29 INFO  time: compiled sample in 63ms[0m
2023.01.01 22:49:29 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:49:29 INFO  time: compiled sample in 44ms[0m
2023.01.01 22:50:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:50:26 INFO  time: compiled sample in 87ms[0m
2023.01.01 22:50:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:50:44 INFO  time: compiled sample in 93ms[0m
Jan 01, 2023 10:50:55 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14742
2023.01.01 22:51:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:51:00 INFO  time: compiled sample in 95ms[0m
2023.01.01 22:51:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:51:03 INFO  time: compiled sample in 0.11s[0m
2023.01.01 22:51:06 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:51:06 INFO  time: compiled sample in 83ms[0m
2023.01.01 22:51:20 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:51:20 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:51:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:51:25 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:51:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:51:31 INFO  time: compiled sample in 0.58s[0m
2023.01.01 22:54:11 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:11 INFO  time: compiled sample in 92ms[0m
2023.01.01 22:54:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:24 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:54:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:31 INFO  time: compiled sample in 0.13s[0m
2023.01.01 22:54:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:39 INFO  time: compiled sample in 0.11s[0m
2023.01.01 22:54:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:40 INFO  time: compiled sample in 56ms[0m
2023.01.01 22:54:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:40 INFO  time: compiled sample in 65ms[0m
2023.01.01 22:54:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:40 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 3h 56m 51.246s)[0m
2023.01.01 22:54:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:40 INFO  time: compiled sample in 54ms[0m
2023.01.01 22:54:42 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:42 INFO  time: compiled sample in 82ms[0m
2023.01.01 22:54:42 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:54:42 INFO  time: compiled sample in 52ms[0m
2023.01.01 22:55:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:55:12 INFO  time: compiled sample in 89ms[0m
2023.01.01 22:55:18 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:55:18 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:55:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:55:25 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:55:27 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:55:27 INFO  time: compiled sample in 94ms[0m
2023.01.01 22:55:28 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:55:28 INFO  time: compiled sample in 89ms[0m
2023.01.01 22:55:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:55:54 INFO  time: compiled sample in 0.12s[0m
2023.01.01 22:56:33 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:56:33 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:56:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:56:37 INFO  time: compiled sample in 94ms[0m
Jan 01, 2023 10:56:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 15223
2023.01.01 22:56:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:56:54 INFO  time: compiled sample in 95ms[0m
2023.01.01 22:56:54 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:56:54 INFO  time: compiled sample in 65ms[0m
2023.01.01 22:56:55 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:56:55 INFO  time: compiled sample in 56ms[0m
2023.01.01 22:58:56 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:58:56 INFO  time: compiled sample in 0.11s[0m
2023.01.01 22:59:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:59:12 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:59:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:59:15 INFO  time: compiled sample in 0.1s[0m
2023.01.01 22:59:19 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:59:19 INFO  time: compiled sample in 0.12s[0m
2023.01.01 22:59:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:59:24 INFO  time: compiled sample in 0.11s[0m
2023.01.01 22:59:58 INFO  compiling sample (1 scala source)[0m
2023.01.01 22:59:58 INFO  time: compiled sample in 0.12s[0m
2023.01.01 23:00:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:00:12 INFO  time: compiled sample in 0.12s[0m
2023.01.01 23:00:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:00:12 INFO  time: compiled sample in 70ms[0m
2023.01.01 23:00:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:00:15 INFO  time: compiled sample in 0.54s[0m
2023.01.01 23:00:20 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 4h 2m 30.043s)[0m
2023.01.01 23:00:20 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 23:00:20 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 23:00:20 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 23:00:21 INFO  Trying to attach to remote debuggee VM localhost:48389 .[0m
2023.01.01 23:00:21 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 23:00:21 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 23:00:24 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 23:00:24 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 23:00:24 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 23:00:24 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 23:00:24 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 23:00:26 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 23:00:26 INFO  Closing debug server tcp://0.0.0.0:36547[0m
2023.01.01 23:01:01 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:01 INFO  time: compiled sample in 0.12s[0m
2023.01.01 23:01:05 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:05 INFO  time: compiled sample in 98ms[0m
2023.01.01 23:01:15 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:15 INFO  time: compiled sample in 96ms[0m
2023.01.01 23:01:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:25 INFO  time: compiled sample in 94ms[0m
2023.01.01 23:01:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:25 INFO  time: compiled sample in 41ms[0m
2023.01.01 23:01:26 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:26 INFO  time: compiled sample in 47ms[0m
2023.01.01 23:01:32 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:32 INFO  time: compiled sample in 97ms[0m
2023.01.01 23:01:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:36 INFO  time: compiled sample in 0.1s[0m
2023.01.01 23:01:47 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:47 INFO  time: compiled sample in 86ms[0m
2023.01.01 23:01:47 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:01:47 INFO  time: compiled sample in 44ms[0m
2023.01.01 23:02:01 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:01 INFO  time: compiled sample in 57ms[0m
2023.01.01 23:02:03 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:03 INFO  time: compiled sample in 56ms[0m
2023.01.01 23:02:07 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:07 INFO  time: compiled sample in 0.11s[0m
2023.01.01 23:02:17 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:17 INFO  time: compiled sample in 80ms[0m
2023.01.01 23:02:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:23 INFO  time: compiled sample in 89ms[0m
2023.01.01 23:02:27 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:27 INFO  time: compiled sample in 50ms[0m
2023.01.01 23:02:28 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:28 INFO  time: compiled sample in 89ms[0m
2023.01.01 23:02:32 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:32 INFO  time: compiled sample in 91ms[0m
2023.01.01 23:02:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:37 INFO  time: compiled sample in 98ms[0m
2023.01.01 23:02:45 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:02:45 INFO  time: compiled sample in 89ms[0m
2023.01.01 23:03:04 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:03:04 INFO  time: compiled sample in 0.49s[0m
2023.01.01 23:03:16 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:03:16 INFO  time: compiled sample in 0.49s[0m
2023.01.01 23:03:20 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 4h 5m 30.504s)[0m
2023.01.01 23:03:20 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 23:03:20 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 23:03:20 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 23:03:22 INFO  Trying to attach to remote debuggee VM localhost:44633 .[0m
2023.01.01 23:03:22 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 23:03:22 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 23:03:25 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 23:03:25 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 23:03:25 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 23:03:25 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 23:03:25 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 23:03:26 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 23:03:26 INFO  Closing debug server tcp://0.0.0.0:40889[0m
2023.01.01 23:05:05 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:05:05 INFO  time: compiled sample in 0.14s[0m
Jan 01, 2023 11:05:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16074
Jan 01, 2023 11:05:31 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16131
Jan 01, 2023 11:05:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16157
Jan 01, 2023 11:05:44 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16225
2023.01.01 23:05:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:05:59 INFO  time: compiled sample in 88ms[0m
2023.01.01 23:08:27 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:27 INFO  time: compiled sample in 91ms[0m
2023.01.01 23:08:32 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:32 INFO  time: compiled sample in 91ms[0m
2023.01.01 23:08:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:37 INFO  time: compiled sample in 82ms[0m
2023.01.01 23:08:37 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:37 INFO  time: compiled sample in 62ms[0m
2023.01.01 23:08:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:39 INFO  time: compiled sample in 62ms[0m
2023.01.01 23:08:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:39 INFO  time: compiled sample in 47ms[0m
2023.01.01 23:08:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:40 INFO  time: compiled sample in 83ms[0m
2023.01.01 23:08:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:40 INFO  time: compiled sample in 41ms[0m
2023.01.01 23:08:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:41 INFO  time: compiled sample in 50ms[0m
2023.01.01 23:08:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:41 INFO  time: compiled sample in 46ms[0m
2023.01.01 23:08:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:43 INFO  time: compiled sample in 56ms[0m
2023.01.01 23:08:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:43 INFO  time: compiled sample in 46ms[0m
2023.01.01 23:08:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:08:44 INFO  time: compiled sample in 58ms[0m
2023.01.01 23:09:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:09:41 INFO  time: compiled sample in 94ms[0m
2023.01.01 23:09:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:09:41 INFO  time: compiled sample in 43ms[0m
2023.01.01 23:09:49 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:09:49 INFO  time: compiled sample in 90ms[0m
2023.01.01 23:09:50 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:09:50 INFO  time: compiled sample in 95ms[0m
2023.01.01 23:09:52 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:09:52 INFO  time: compiled sample in 83ms[0m
2023.01.01 23:09:59 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:09:59 INFO  time: compiled sample in 75ms[0m
2023.01.01 23:11:28 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:11:28 INFO  time: compiled sample in 70ms[0m
2023.01.01 23:11:39 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:11:39 INFO  time: compiled sample in 89ms[0m
2023.01.01 23:11:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:11:44 INFO  time: compiled sample in 0.1s[0m
2023.01.01 23:11:48 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:11:48 INFO  time: compiled sample in 80ms[0m
2023.01.01 23:11:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:11:53 INFO  time: compiled sample in 78ms[0m
2023.01.01 23:12:00 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:12:00 INFO  time: compiled sample in 89ms[0m
2023.01.01 23:13:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:12 INFO  time: compiled sample in 75ms[0m
2023.01.01 23:13:23 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:23 INFO  time: compiled sample in 86ms[0m
2023.01.01 23:13:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:24 INFO  time: compiled sample in 93ms[0m
2023.01.01 23:13:24 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:24 INFO  time: compiled sample in 43ms[0m
2023.01.01 23:13:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:25 INFO  time: compiled sample in 40ms[0m
2023.01.01 23:13:40 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:40 INFO  time: compiled sample in 78ms[0m
2023.01.01 23:13:47 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:47 INFO  time: compiled sample in 82ms[0m
2023.01.01 23:13:50 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:50 INFO  time: compiled sample in 88ms[0m
2023.01.01 23:13:51 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:13:51 INFO  time: compiled sample in 82ms[0m
2023.01.01 23:14:14 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:14 INFO  time: compiled sample in 97ms[0m
2023.01.01 23:14:22 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:22 INFO  time: compiled sample in 85ms[0m
2023.01.01 23:14:31 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:31 INFO  time: compiled sample in 84ms[0m
2023.01.01 23:14:35 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:35 INFO  time: compiled sample in 90ms[0m
2023.01.01 23:14:38 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:38 INFO  time: compiled sample in 79ms[0m
2023.01.01 23:14:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:41 INFO  time: compiled sample in 81ms[0m
2023.01.01 23:14:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:41 INFO  time: compiled sample in 41ms[0m
2023.01.01 23:14:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:43 INFO  time: compiled sample in 52ms[0m
2023.01.01 23:14:43 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:43 INFO  time: compiled sample in 47ms[0m
2023.01.01 23:14:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:44 INFO  time: compiled sample in 55ms[0m
2023.01.01 23:14:44 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:45 INFO  time: compiled sample in 55ms[0m
2023.01.01 23:14:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:14:53 INFO  time: compiled sample in 65ms[0m
2023.01.01 23:15:22 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:15:22 INFO  time: compiled sample in 57ms[0m
2023.01.01 23:15:25 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:15:25 INFO  time: compiled sample in 91ms[0m
2023.01.01 23:15:36 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:15:36 INFO  time: compiled sample in 88ms[0m
2023.01.01 23:15:41 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:15:41 INFO  time: compiled sample in 93ms[0m
2023.01.01 23:16:04 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:16:04 INFO  time: compiled sample in 0.55s[0m
2023.01.01 23:16:11 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 4h 18m 21.053s)[0m
2023.01.01 23:16:11 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 23:16:11 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 23:16:11 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 23:16:12 INFO  Trying to attach to remote debuggee VM localhost:57129 .[0m
2023.01.01 23:16:12 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 23:16:12 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 23:16:15 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 23:16:15 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 23:16:15 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 23:16:15 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 23:16:15 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 23:16:17 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (172.25.125.240 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 23:16:17 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 23:16:17 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 23:16:17 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:52)[0m
2023.01.01 23:16:17 ERROR 	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)[0m
2023.01.01 23:16:17 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1931)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1274)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1274)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 23:16:17 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 23:16:17 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 23:16:17 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 23:16:17 ERROR [0m
2023.01.01 23:16:17 ERROR Driver stacktrace:[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 23:16:17 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 23:16:17 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.count(RDD.scala:1274)[0m
2023.01.01 23:16:17 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:61)[0m
2023.01.01 23:16:17 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 23:16:17 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 23:16:17 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 23:16:17 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 23:16:17 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:52)[0m
2023.01.01 23:16:17 ERROR 	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)[0m
2023.01.01 23:16:17 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1931)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1274)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1274)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 23:16:17 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 23:16:17 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 23:16:17 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 23:16:17 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 23:16:17 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 23:16:17 INFO  Closing debug server tcp://0.0.0.0:46731[0m
2023.01.01 23:16:38 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:16:38 INFO  time: compiled sample in 0.52s[0m
2023.01.01 23:18:53 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:18:53 INFO  time: compiled sample in 0.1s[0m
2023.01.01 23:18:55 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:18:55 INFO  time: compiled sample in 87ms[0m
2023.01.01 23:18:55 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:18:55 INFO  time: compiled sample in 41ms[0m
Jan 01, 2023 11:19:01 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.debug.DebugProvider$WorkspaceErrorsException$: Cannot run class, since the workspace has errors.
java.util.concurrent.CompletionException: scala.meta.internal.metals.debug.DebugProvider$WorkspaceErrorsException$: Cannot run class, since the workspace has errors.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.uniAcceptNow(CompletableFuture.java:743)
	at java.base/java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:731)
	at java.base/java.util.concurrent.CompletableFuture.thenAcceptAsync(CompletableFuture.java:2112)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.thenAccept(FutureConvertersImpl.scala:37)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleRequest(RemoteEndpoint.java:279)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:190)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: scala.meta.internal.metals.debug.DebugProvider$WorkspaceErrorsException$: Cannot run class, since the workspace has errors.
	at scala.meta.internal.metals.debug.DebugProvider$WorkspaceErrorsException$.<clinit>(DebugProvider.scala:873)
	at scala.meta.internal.metals.debug.DebugProvider.ensureNoWorkspaceErrors(DebugProvider.scala:383)
	at scala.meta.internal.metals.MetalsLanguageServer.executeCommand(MetalsLanguageServer.scala:1943)
	at jdk.internal.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:65)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.request(GenericEndpoint.java:120)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleRequest(RemoteEndpoint.java:261)
	... 9 more

2023.01.01 23:19:01 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:19:01 INFO  time: compiled sample in 0.12s[0m
2023.01.01 23:19:12 INFO  compiling sample (1 scala source)[0m
2023.01.01 23:19:12 INFO  time: compiled sample in 0.55s[0m
2023.01.01 23:19:16 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 4h 21m 26.331s)[0m
2023.01.01 23:19:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.01 23:19:16 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.01 23:19:16 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 23:19:17 INFO  Trying to attach to remote debuggee VM localhost:47377 .[0m
2023.01.01 23:19:17 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.01 23:19:17 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.01 23:19:21 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.01 23:19:21 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.01 23:19:21 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.01 23:19:21 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.01 23:19:21 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.01 23:19:22 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (172.25.125.240 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 23:19:22 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 23:19:22 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 23:19:22 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:52)[0m
2023.01.01 23:19:22 ERROR 	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)[0m
2023.01.01 23:19:22 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1931)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1274)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1274)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 23:19:22 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 23:19:22 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 23:19:22 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 23:19:22 ERROR [0m
2023.01.01 23:19:22 ERROR Driver stacktrace:[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.01 23:19:22 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.01 23:19:22 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.count(RDD.scala:1274)[0m
2023.01.01 23:19:22 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:61)[0m
2023.01.01 23:19:22 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.01 23:19:22 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.01 23:19:22 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.01 23:19:22 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.01 23:19:22 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:52)[0m
2023.01.01 23:19:22 ERROR 	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)[0m
2023.01.01 23:19:22 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1931)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1274)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1274)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.01 23:19:22 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.01 23:19:22 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.01 23:19:22 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.01 23:19:22 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.01 23:19:22 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.01 23:19:22 INFO  Closing debug server tcp://0.0.0.0:41355[0m
2023.01.01 23:19:30 INFO  shutting down Metals[0m
2023.01.01 23:19:30 INFO  Shut down connection with build server.[0m
2023.01.01 23:19:30 INFO  Shut down connection with build server.[0m
2023.01.02 11:10:51 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/lsp.trace.json or /home/mnapps/.cache/metals/lsp.trace.json[0m
2023.01.02 11:10:51 INFO  logging to file /home/mnapps/DominanceQueries/.metals/metals.log[0m
2023.01.02 11:10:51 INFO  Started: Metals version 0.11.9 in workspace '/home/mnapps/DominanceQueries' for client Visual Studio Code 1.74.2.[0m
2023.01.02 11:10:52 INFO  time: initialize in 1.44s[0m
2023.01.02 11:10:54 INFO  Attempting to connect to the build server...[0m
2023.01.02 11:10:54 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.02 11:10:54 INFO  skipping build import with status 'Installed'[0m
2023.01.02 11:10:58 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.02 11:10:58 INFO  Attempting to connect to the build server...[0m
2023.01.02 11:10:58 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.02 11:10:58 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/project/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.02 11:10:58 INFO  time: Connected to build server in 4.34s[0m
2023.01.02 11:10:58 INFO  Connected to Build server: Bloop v1.5.4[0m
2023.01.02 11:11:00 INFO  no build target found for /home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala. Using presentation compiler with project's scala-library version: 3.2.0[0m
2023.01.02 11:11:00 INFO  time: code lens generation in 5.37s[0m
2023.01.02 11:11:00 INFO  time: Imported build in 0.17s[0m
2023.01.02 11:11:03 INFO  time: indexed workspace in 2.73s[0m
2023.01.02 15:43:47 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.02 15:43:47 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.02 15:43:47 INFO  Connected to Build server: Bloop v1.5.4[0m
2023.01.02 15:43:47 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.02 15:43:47 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/project/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
Jan 02, 2023 6:00:51 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.01.02 18:01:24 INFO  shutting down Metals[0m
2023.01.02 18:01:25 INFO  Shut down connection with build server.[0m
2023.01.02 18:01:25 INFO  Shut down connection with build server.[0m
Jan 02, 2023 6:01:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint notify
INFO: Failed to send notification message.
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.nio.channels.AsynchronousCloseException
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.notify(RemoteEndpoint.java:126)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.sendCancelNotification(RemoteEndpoint.java:180)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint$1.cancel(RemoteEndpoint.java:150)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$register$2(BuildServerConnection.scala:321)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)
	at scala.util.Try$.apply(Try.scala:210)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$register$1(BuildServerConnection.scala:321)
	at scala.meta.internal.metals.Cancelable$$anon$1.cancel(Cancelable.scala:18)
	at scala.meta.internal.metals.Cancelable$.$anonfun$cancelAll$1(Cancelable.scala:29)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at scala.meta.internal.metals.Cancelable$.cancelAll(Cancelable.scala:28)
	at scala.meta.internal.metals.MutableCancelable.cancel(MutableCancelable.scala:25)
	at scala.meta.internal.metals.BuildServerConnection.cancel(BuildServerConnection.scala:257)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1(BuildServerConnection.scala:122)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1$adapted(BuildServerConnection.scala:115)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.nio.channels.AsynchronousCloseException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.base/sun.nio.ch.SinkChannelImpl.endWrite(SinkChannelImpl.java:241)
	at java.base/sun.nio.ch.SinkChannelImpl.write(SinkChannelImpl.java:259)
	at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)
	at java.base/java.nio.channels.Channels.writeFully(Channels.java:94)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:172)
	at java.base/java.io.OutputStream.write(OutputStream.java:122)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:152)
	at scala.meta.internal.metals.ClosableOutputStream.write(ClosableOutputStream.scala:26)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:137)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:67)
	... 19 more

Jan 02, 2023 6:01:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint notify
INFO: Failed to send notification message.
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.nio.channels.AsynchronousCloseException
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.notify(RemoteEndpoint.java:126)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.sendCancelNotification(RemoteEndpoint.java:180)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint$1.cancel(RemoteEndpoint.java:150)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$register$2(BuildServerConnection.scala:321)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)
	at scala.util.Try$.apply(Try.scala:210)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$register$1(BuildServerConnection.scala:321)
	at scala.meta.internal.metals.Cancelable$$anon$1.cancel(Cancelable.scala:18)
	at scala.meta.internal.metals.Cancelable$.$anonfun$cancelAll$1(Cancelable.scala:29)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at scala.meta.internal.metals.Cancelable$.cancelAll(Cancelable.scala:28)
	at scala.meta.internal.metals.MutableCancelable.cancel(MutableCancelable.scala:25)
	at scala.meta.internal.metals.BuildServerConnection.cancel(BuildServerConnection.scala:258)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1(BuildServerConnection.scala:122)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1$adapted(BuildServerConnection.scala:115)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.nio.channels.AsynchronousCloseException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.base/sun.nio.ch.SinkChannelImpl.endWrite(SinkChannelImpl.java:241)
	at java.base/sun.nio.ch.SinkChannelImpl.write(SinkChannelImpl.java:259)
	at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)
	at java.base/java.nio.channels.Channels.writeFully(Channels.java:94)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:172)
	at java.base/java.io.OutputStream.write(OutputStream.java:122)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:152)
	at scala.meta.internal.metals.ClosableOutputStream.write(ClosableOutputStream.scala:26)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:137)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:67)
	... 19 more

2023.01.02 18:01:25 INFO  Cancelling compilation on Bloop server[0m
2023.01.02 18:01:35 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/lsp.trace.json or /home/mnapps/.cache/metals/lsp.trace.json[0m
2023.01.02 18:01:35 INFO  logging to file /home/mnapps/DominanceQueries/.metals/metals.log[0m
2023.01.02 18:01:35 INFO  Started: Metals version 0.11.9 in workspace '/home/mnapps/DominanceQueries' for client Visual Studio Code 1.74.2.[0m
2023.01.02 18:01:36 INFO  time: initialize in 1.23s[0m
2023.01.02 18:01:38 INFO  Attempting to connect to the build server...[0m
2023.01.02 18:01:38 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.02 18:01:38 INFO  skipping build import with status 'Installed'[0m
2023.01.02 18:01:38 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.02 18:01:38 INFO  Attempting to connect to the build server...[0m
2023.01.02 18:01:38 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.02 18:01:38 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/project/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.02 18:01:38 INFO  time: Connected to build server in 0.58s[0m
2023.01.02 18:01:38 INFO  Connected to Build server: Bloop v1.5.4[0m
2023.01.02 18:01:38 INFO  time: Imported build in 0.16s[0m
2023.01.02 18:01:41 INFO  no build target found for /home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala. Using presentation compiler with project's scala-library version: 3.2.0[0m
2023.01.02 18:01:43 INFO  time: code lens generation in 4.17s[0m
2023.01.02 18:01:45 INFO  time: indexed workspace in 6.59s[0m
2023.01.02 18:01:46 INFO  compiling sample (1 scala source)[0m
2023.01.02 18:01:52 INFO  time: compiled sample in 5.61s[0m
Jan 02, 2023 6:02:07 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.01.02 18:05:31 INFO  shutting down Metals[0m
2023.01.02 18:05:31 INFO  Shut down connection with build server.[0m
2023.01.02 18:05:31 INFO  Shut down connection with build server.[0m
2023.01.02 18:05:51 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/lsp.trace.json or /home/mnapps/.cache/metals/lsp.trace.json[0m
2023.01.02 18:05:51 INFO  logging to file /home/mnapps/DominanceQueries/.metals/metals.log[0m
2023.01.02 18:05:51 INFO  Started: Metals version 0.11.9 in workspace '/home/mnapps/DominanceQueries' for client Visual Studio Code 1.74.2.[0m
2023.01.02 18:05:53 INFO  time: initialize in 1.52s[0m
2023.01.02 18:05:55 INFO  Attempting to connect to the build server...[0m
2023.01.02 18:05:55 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.02 18:05:55 INFO  skipping build import with status 'Installed'[0m
2023.01.02 18:05:59 INFO  no build target found for /home/mnapps/DominanceQueries/src/main/scala/DominanceQueries.scala. Using presentation compiler with project's scala-library version: 3.2.0[0m
2023.01.02 18:05:59 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.02 18:05:59 INFO  Attempting to connect to the build server...[0m
2023.01.02 18:05:59 INFO  Bloop uses /usr/lib/jvm/java-11-openjdk-amd64 defined at /home/mnapps/.bloop/bloop.json[0m
2023.01.02 18:05:59 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/project/.metals/bsp.trace.json or /home/mnapps/.cache/metals/bsp.trace.json[0m
2023.01.02 18:05:59 INFO  time: Connected to build server in 4.29s[0m
2023.01.02 18:05:59 INFO  Connected to Build server: Bloop v1.5.4[0m
2023.01.02 18:05:59 INFO  time: Imported build in 0.29s[0m
2023.01.02 18:06:01 INFO  time: code lens generation in 5.2s[0m
2023.01.02 18:06:03 INFO  time: indexed workspace in 4.22s[0m
Jan 02, 2023 6:07:35 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.01.02 18:30:14 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 24m 15.236s)[0m
2023.01.02 18:30:14 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.02 18:30:14 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.02 18:30:15 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.02 18:30:17 INFO  Trying to attach to remote debuggee VM localhost:37537 .[0m
2023.01.02 18:30:17 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.02 18:30:17 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.02 18:30:21 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.02 18:30:21 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.02 18:30:21 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.02 18:30:21 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.02 18:30:21 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.02 18:30:23 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (172.25.120.128 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.02 18:30:23 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.02 18:30:23 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.02 18:30:23 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:52)[0m
2023.01.02 18:30:23 ERROR 	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)[0m
2023.01.02 18:30:23 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1931)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1274)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1274)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.02 18:30:23 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.02 18:30:23 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.02 18:30:23 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.02 18:30:23 ERROR [0m
2023.01.02 18:30:23 ERROR Driver stacktrace:[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.02 18:30:23 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.02 18:30:23 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.count(RDD.scala:1274)[0m
2023.01.02 18:30:23 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:61)[0m
2023.01.02 18:30:23 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.02 18:30:23 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.02 18:30:23 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.02 18:30:23 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.02 18:30:23 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:52)[0m
2023.01.02 18:30:23 ERROR 	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)[0m
2023.01.02 18:30:23 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1931)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1274)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1274)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.02 18:30:23 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.02 18:30:23 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.02 18:30:23 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.02 18:30:23 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.02 18:30:23 INFO  Closing debug server tcp://0.0.0.0:39429[0m
2023.01.02 18:30:24 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.02 18:30:41 INFO  Deduplicating compilation of sample from bsp client 'Metals 0.11.9' (since 24m 42.234s)[0m
2023.01.02 18:30:41 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-server.trace.json or /home/mnapps/.cache/metals/dap-server.trace.json[0m
2023.01.02 18:30:41 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/mnapps/DominanceQueries/.metals/dap-client.trace.json or /home/mnapps/.cache/metals/dap-client.trace.json[0m
2023.01.02 18:30:41 INFO  Starting debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.02 18:30:43 INFO  Trying to attach to remote debuggee VM localhost:39913 .[0m
2023.01.02 18:30:43 INFO  Attaching to debuggee VM succeeded.[0m
2023.01.02 18:30:43 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.01.02 18:30:46 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.01.02 18:30:46 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/mnapps/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.01.02 18:30:46 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.01.02 18:30:46 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.01.02 18:30:46 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.01.02 18:30:48 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (172.25.120.128 executor driver): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.02 18:30:48 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.02 18:30:48 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.02 18:30:48 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:52)[0m
2023.01.02 18:30:48 ERROR 	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)[0m
2023.01.02 18:30:48 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1931)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1274)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1274)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.02 18:30:48 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.02 18:30:48 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.02 18:30:48 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.02 18:30:48 ERROR [0m
2023.01.02 18:30:48 ERROR Driver stacktrace:[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
2023.01.02 18:30:48 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
2023.01.02 18:30:48 ERROR 	at scala.Option.foreach(Option.scala:437)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.count(RDD.scala:1274)[0m
2023.01.02 18:30:48 ERROR 	at DominanceQueries.DominanceQueries$.main(DominanceQueries.scala:61)[0m
2023.01.02 18:30:48 ERROR 	at DominanceQueries.DominanceQueries.main(DominanceQueries.scala)[0m
2023.01.02 18:30:48 ERROR Caused by: org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: [0m
2023.01.02 18:30:48 ERROR (1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.[0m
2023.01.02 18:30:48 ERROR (2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.errors.SparkCoreErrors$.rddLacksSparkContextError(SparkCoreErrors.scala:105)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.sc(RDD.scala:96)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.filter(RDD.scala:430)[0m
2023.01.02 18:30:48 ERROR 	at DominanceQueries.DominanceQueries$.$anonfun$main$3(DominanceQueries.scala:52)[0m
2023.01.02 18:30:48 ERROR 	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)[0m
2023.01.02 18:30:48 ERROR 	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1931)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1274)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1274)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
2023.01.02 18:30:48 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
2023.01.02 18:30:48 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
2023.01.02 18:30:48 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
2023.01.02 18:30:48 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.01.02 18:30:48 INFO  Canceling debug proxy for [DominanceQueries.DominanceQueries][0m
2023.01.02 18:30:48 INFO  Closing debug server tcp://0.0.0.0:39465[0m
Jan 02, 2023 6:30:48 PM org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Socket closed
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Socket closed
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:146)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:65)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.net.SocketException: Socket closed
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:113)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 16 more

2023.01.02 18:31:30 INFO  compiling sample (1 scala source)[0m
2023.01.02 18:31:33 INFO  time: compiled sample in 3.3s[0m
